{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ObservabilityStack Documentation","text":"<p>Welcome to the ObservabilityStack documentation! This is a GitOps-managed observability platform built for local Kubernetes clusters, designed for development, learning, and experimentation.</p>"},{"location":"#what-is-observabilitystack","title":"What is ObservabilityStack?","text":"<p>A complete observability stack featuring:</p> <ul> <li>OpenTelemetry Collector - Unified telemetry pipeline</li> <li>Grafana - Visualization and dashboards</li> <li>Loki - Log aggregation with multi-tenant support</li> <li>Tempo - Distributed tracing</li> <li>Prometheus - Metrics collection</li> <li>ArgoCD - GitOps deployment management</li> </ul> <p>All components are managed through a Helm umbrella chart pattern and deployed via ArgoCD for a true GitOps experience.</p>"},{"location":"#quick-navigation","title":"Quick Navigation","text":""},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Installation Guide - Setup from zero to running system</li> <li>Usage Guide - Send and query telemetry data</li> </ul>"},{"location":"#understanding-the-system","title":"Understanding the System","text":"<ul> <li>Architecture Guide - Umbrella chart pattern and design decisions</li> <li>Git Workflow - Branch management and deployment workflows</li> </ul>"},{"location":"#advanced-topics","title":"Advanced Topics","text":"<ul> <li>Batch Optimization - Performance tuning results</li> <li>Mimir Setup - Long-term metrics storage</li> </ul>"},{"location":"#when-things-go-wrong","title":"When Things Go Wrong","text":"<ul> <li>Troubleshooting Guide - Emergency procedures and debugging</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<p>\u2705 GitOps-Native - All changes managed through Git commits \u2705 Multi-Tenant Ready - Isolated data with tenant support \u2705 Resource Optimized - Runs efficiently on local machines \u2705 Educational - Perfect for learning observability concepts \u2705 Production Patterns - Uses real-world architectural patterns  </p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># Clone the repository\ngit clone https://github.com/fiddeb/observabilitystack.git\ncd observabilitystack\n\n# Install everything with one command\n./scripts/install_argo.sh\n</code></pre> <p>Access your stack: - Grafana: http://grafana.k8s.test - ArgoCD: http://argocd.k8s.test - Prometheus: http://prometheus.k8s.test - Loki: http://loki.k8s.test</p>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<p>This documentation is organized into focused guides:</p> Guide Purpose Installation Prerequisites, DNS setup, installation steps Architecture Umbrella chart pattern, GitOps workflow, configuration Usage Sending logs/metrics/traces, querying data, dashboards Git Workflow Feature branches, safe merging, ArgoCD integration Troubleshooting Common issues, debugging, emergency procedures Batch Optimization Performance tuning and results Mimir Setup Long-term metrics storage"},{"location":"#architecture-at-a-glance","title":"Architecture at a Glance","text":"<pre><code>flowchart LR\n    Git[Git Repository] --&gt;|Sync| ArgoCD\n    ArgoCD --&gt;|Deploy| Helm[Helm Umbrella Chart]\n    Helm --&gt;|Install| Stack[Observability Stack]\n\n    Apps[Your Apps] --&gt;|Telemetry| OTel[OTel Collector]\n    OTel --&gt;|Logs| Loki\n    OTel --&gt;|Metrics| Prometheus\n    OTel --&gt;|Traces| Tempo\n\n    Grafana --&gt;|Query| Loki\n    Grafana --&gt;|Query| Prometheus\n    Grafana --&gt;|Query| Tempo\n\n    User[You] --&gt;|Browse| Grafana</code></pre> <p>Key Concepts: - Umbrella Chart - Single Helm chart manages all components as dependencies - Multi-Values - Configuration split across files (one per component) - GitOps - ArgoCD syncs from Git, ensuring declarative infrastructure - Local First - Designed for local Kubernetes (Rancher Desktop, minikube, k3d)</p>"},{"location":"#platform-support","title":"Platform Support","text":"Platform Status Notes macOS \u2705 Fully Supported Wildcard DNS via dnsmasq Linux \u2705 Fully Supported Wildcard DNS via dnsmasq Windows \u26a0\ufe0f Limited Static hosts file only (no wildcard DNS)"},{"location":"#need-help","title":"Need Help?","text":"<ul> <li>Installation issues? \u2192 Installation Guide</li> <li>How do I...? \u2192 Usage Guide</li> <li>Something broken? \u2192 Troubleshooting Guide</li> <li>Understanding design? \u2192 Architecture Guide</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions! Please: 1. Fork the repository 2. Create a feature branch 3. Follow the Git Workflow 4. Submit a pull request</p>"},{"location":"#license","title":"License","text":"<p>MIT License - See LICENSE for details.</p> <p>Ready to get started? Head to the Installation Guide \u2192</p>"},{"location":"advanced/BATCH_OPTIMIZATION/","title":"OpenTelemetry Collector Batch Optimization Results","text":""},{"location":"advanced/BATCH_OPTIMIZATION/#summary","title":"Summary","text":"<p>I optimized the log ingestion pipeline from 13.4k eps to 67.5k eps (403% improvement). It took systematic batch processor tuning and throwing more CPU at Loki.</p>"},{"location":"advanced/BATCH_OPTIMIZATION/#performance-progression","title":"Performance Progression","text":"Test Config Result Change Baseline Batch 128/128/200ms, 250m CPU, 2Gi mem 13.4k eps - Test 1 Batch 512/512/100ms, 1000m CPU, 2Gi mem 34.8k eps +160% Test 2 Batch 2048/4096/50ms, 2000m CPU, 4Gi mem, 40 workers, 5000 queue 68.7k eps +97% Test 3 Batch 4096/8192/25ms, 80% mem limit 67.0k eps -2.5% \u274c Final Batch 4096/8192/50ms, 75% mem limit, Loki defaults 67.5k eps Stable \u2705"},{"location":"advanced/BATCH_OPTIMIZATION/#what-changed","title":"What Changed","text":""},{"location":"advanced/BATCH_OPTIMIZATION/#opentelemetry-collector","title":"OpenTelemetry Collector","text":"<p>Batch Processor: - <code>send_batch_size: 128 \u2192 4096</code> (32x larger) - <code>send_batch_max_size: 128 \u2192 8192</code> (64x larger) - <code>timeout: 200ms \u2192 50ms</code> (4x faster)</p> <p>Why this worked: Bigger batches mean fewer HTTP requests to Loki. Network overhead is expensive - bundling more logs per request made a huge difference.</p> <p>Memory Limiter: - <code>limit_percentage: 75%</code> (down from 80%) - <code>spike_limit_percentage: 25%</code> (down from 30%) - <code>check_interval: 2s</code> (up from 1s)</p> <p>Why this worked: Checking memory every second was eating CPU for no good reason. 2s checks are plenty fast, and 75%/25% gives enough headroom without throttling too early.</p> <p>Resources: - <code>cpu: 250m \u2192 2000m</code> (8x) - <code>memory: 2Gi \u2192 4Gi</code> (2x)</p> <p>Why it worked: Batch processor needs CPU for serialization and memory for buffering large batches before export.</p> <p>Sending Queue: - <code>num_consumers: 10 \u2192 40</code> (4x parallelism) - <code>queue_size: 1000 \u2192 5000</code> (5x buffer)</p> <p>Why it worked: 40 parallel workers match high throughput demand. Large queue prevents \"queue is full\" errors during burst traffic.</p>"},{"location":"advanced/BATCH_OPTIMIZATION/#loki","title":"Loki","text":"<p>Resources: - <code>cpu: 500m \u2192 6000m</code> (12x) - <code>memory: 1Gi \u2192 8Gi</code> (8x) - <code>GOMEMLIMIT: 7500MiB</code></p> <p>Why this worked: Loki is CPU-hungry when ingesting OTLP logs. More cores = more parallel processing. Sometimes the answer is just \"throw more hardware at it.\"</p> <p>Ingestion Limits: - <code>ingestion_rate_mb: 4 \u2192 64</code> (16x) - <code>per_stream_rate_limit: 4MB \u2192 64MB</code> (16x)</p> <p>Why it worked: Removed artificial rate limiting that was throttling valid high-volume ingestion.</p> <p>Chunk Settings: - Default 1.5MB chunks (I tried 2MB, didn't help) - Default idle/age timings</p> <p>Why this worked: Loki's defaults are there for a reason. My \"clever\" custom chunk tuning (2MB chunks, 15m idle, 2h age) actually made things worse by keeping data in memory too long.</p>"},{"location":"advanced/BATCH_OPTIMIZATION/#k6-test-configuration","title":"k6 Test Configuration","text":"<p>Label Cardinality: - <code>app: 2 \u2192 1</code> (single stream)</p> <p>Why it worked: Eliminated stream creation overhead. Single stream maximizes write throughput by removing per-stream processing.</p> <p>Load Profile: - Low volume: 1 VU, 30s - High volume: 12 VUs, 90s - Burst: 18 VUs, 40s (reduced from 25 due to TCP port exhaustion)</p>"},{"location":"advanced/BATCH_OPTIMIZATION/#what-didnt-work","title":"What Didn't Work","text":""},{"location":"advanced/BATCH_OPTIMIZATION/#timeout-too-aggressive","title":"Timeout Too Aggressive","text":"<ul> <li><code>timeout: 25ms</code> made things worse (-2.5% throughput)</li> <li>What I learned: Batches need time to fill up. 25ms was too impatient - it sent half-full batches and wasted the benefit of batching.</li> <li>Fix: Went back to 50ms</li> </ul>"},{"location":"advanced/BATCH_OPTIMIZATION/#memory-limiter-too-permissive","title":"Memory Limiter Too Permissive","text":"<ul> <li><code>80%/30%/1s</code> caused regression</li> <li>Root cause: 1s check interval added CPU overhead, 80% triggered throttling too late</li> <li>Fix: 75%/25%/2s provides headroom without constant checking</li> </ul>"},{"location":"advanced/BATCH_OPTIMIZATION/#loki-chunk-tuning","title":"Loki Chunk Tuning","text":"<ul> <li>2MB chunks + long retention made things worse</li> <li>What I learned: I thought keeping chunks in memory longer would reduce disk I/O. Wrong. It just delayed writes and slowed down ingestion.</li> <li>Fix: Stick with Loki's defaults</li> </ul>"},{"location":"advanced/BATCH_OPTIMIZATION/#bottlenecks","title":"Bottlenecks","text":"<ol> <li>CPU ceiling: I'm using 8 cores total (2000m OTel + 6000m Loki). To go faster, I'd need more CPU.</li> <li>TCP port exhaustion: macOS localhost connections ran out at 18 VUs. Need sysctl tuning to go higher.</li> <li>Batch size sweet spot: 4096/8192 was optimal. Bigger batches didn't help.</li> </ol>"},{"location":"advanced/BATCH_OPTIMIZATION/#production-recommendations","title":"Production Recommendations","text":""},{"location":"advanced/BATCH_OPTIMIZATION/#optimal-configuration","title":"Optimal Configuration","text":"<pre><code># opentelemetry-collector.yaml\nprocessors:\n  memory_limiter:\n    check_interval: 2s\n    limit_percentage: 75\n    spike_limit_percentage: 25\n  batch:\n    send_batch_size: 4096\n    send_batch_max_size: 8192\n    timeout: 50ms\n\nexporters:\n  otlphttp/default:\n    sending_queue:\n      num_consumers: 40\n      queue_size: 5000\n    retry_on_failure:\n      initial_interval: 500ms\n      max_interval: 10s\n\nresources:\n  limits:\n    cpu: 2000m\n    memory: 4Gi\n</code></pre> <pre><code># loki.yaml\nsingleBinary:\n  resources:\n    limits:\n      cpu: 6000m\n      memory: 8Gi\n  extraEnv:\n    - name: GOMEMLIMIT\n      value: 7500MiB\n\nlimits_config:\n  ingestion_rate_mb: 64\n  per_stream_rate_limit: 64MB\n  max_streams_per_user: 50000\n\ningester:\n  chunk_encoding: snappy  # Use defaults for other settings\n</code></pre>"},{"location":"advanced/BATCH_OPTIMIZATION/#what-i-learned","title":"What I Learned","text":"<ol> <li>Batch size matters a lot: 32x larger batches gave ~5x throughput. Networking is expensive.</li> <li>CPU &gt; Memory for Loki: More cores helped way more than more RAM.</li> <li>Trust the defaults: Loki's settings beat my \"optimizations.\"</li> <li>Timeout is a tradeoff: 50ms balances latency vs throughput. Faster isn't always better.</li> <li>Parallel workers help: 40 consumers handled burst load without queue overflow.</li> </ol>"},{"location":"advanced/BATCH_OPTIMIZATION/#test-methodology","title":"Test Methodology","text":"<ul> <li>Tool: k6 with xk6-loki extension</li> <li>Duration: 180s per test (30s + 90s + 50s scenarios)</li> <li>Success criteria: 100% success rate, P95 &lt;500ms</li> <li>Metric: <code>loki_client_lines.rate</code> (events per second)</li> <li>Validation: Zero errors in OTel Collector logs, no queue overflow</li> </ul>"},{"location":"advanced/BATCH_OPTIMIZATION/#final-metrics","title":"Final Metrics","text":"<ul> <li>Throughput: 67.5k eps</li> <li>Success rate: 100%</li> <li>P95 latency: 133ms</li> <li>Avg latency: 59ms</li> <li>CPU usage: ~80% OTel, ~90% Loki</li> <li>Memory usage: ~3.3Gi OTel, ~7Gi Loki</li> </ul> <p>Date: 2025-11-26 Environment: Rancher Desktop, macOS, 6 CPU cores allocated</p>"},{"location":"advanced/MIMIR_SETUP/","title":"Mimir Integration - Monolithic Mode","text":""},{"location":"advanced/MIMIR_SETUP/#overview","title":"Overview","text":"<p>I added Mimir to the stack in monolithic mode using NGDATA's fork of Grafana Mimir, which supports single-pod deployments.</p> <ul> <li>Chart: <code>mimir-distributed</code> v5.6.0 (from Grafana Helm repo)</li> <li>Deployment Mode: Monolithic (one pod runs all components)</li> <li>Storage: Local filesystem (persistent volume)</li> <li>Ingress: <code>http://mimir.k8s.test</code></li> </ul>"},{"location":"advanced/MIMIR_SETUP/#enable-mimir","title":"Enable Mimir","text":""},{"location":"advanced/MIMIR_SETUP/#1-update-chart-dependencies","title":"1. Update Chart Dependencies","text":"<pre><code>cd helm/stackcharts\nhelm dependency update\ncd ../..\n</code></pre>"},{"location":"advanced/MIMIR_SETUP/#2-enable-in-baseyaml","title":"2. Enable in base.yaml","text":"<p>Edit <code>helm/stackcharts/values/base.yaml</code>:</p> <pre><code>mimir:\n  enabled: true\n</code></pre>"},{"location":"advanced/MIMIR_SETUP/#3-deploy-via-argocd","title":"3. Deploy via ArgoCD","text":"<pre><code>./scripts/force_argo_sync.sh\n</code></pre> <p>Or manually:</p> <pre><code>argocd app sync observability-stack --force\n</code></pre>"},{"location":"advanced/MIMIR_SETUP/#verify-installation","title":"Verify Installation","text":"<pre><code># Check pods\nkubectl get pods -n observability-lab | grep mimir\n\n# Expected output:\n# mimir-0                    1/1     Running   0          2m\n# mimir-nginx-xxxxx          1/1     Running   0          2m\n\n# Test endpoints\ncurl http://mimir.k8s.test/ready\ncurl http://mimir.k8s.test/metrics\n</code></pre>"},{"location":"advanced/MIMIR_SETUP/#usage","title":"Usage","text":""},{"location":"advanced/MIMIR_SETUP/#send-metrics-via-prometheus-remote-write","title":"Send Metrics via Prometheus Remote Write","text":"<p>Configure a Prometheus instance to send metrics to Mimir:</p> <pre><code># prometheus-config.yaml\nremote_write:\n  - url: http://mimir-nginx/api/v1/push\n</code></pre>"},{"location":"advanced/MIMIR_SETUP/#query-metrics-via-grafana","title":"Query Metrics via Grafana","text":"<p>Mimir is already configured as a datasource in Grafana: - Name: Mimir - URL: <code>http://mimir-nginx/prometheus</code> - Type: Prometheus (Mimir-compatible)</p> <p>Visit <code>http://grafana.k8s.test</code> and select \"Mimir\" as the datasource in Explore.</p>"},{"location":"advanced/MIMIR_SETUP/#query-metrics-via-api","title":"Query Metrics via API","text":"<pre><code># PromQL query\ncurl -G http://mimir.k8s.test/prometheus/api/v1/query \\\n  --data-urlencode 'query=up'\n\n# Label values\ncurl http://mimir.k8s.test/prometheus/api/v1/label/__name__/values\n</code></pre>"},{"location":"advanced/MIMIR_SETUP/#configuration","title":"Configuration","text":""},{"location":"advanced/MIMIR_SETUP/#key-settings","title":"Key Settings","text":"<p>Configure in <code>helm/stackcharts/values/mimir.yaml</code>:</p> <pre><code>mimir:\n  monolithic:\n    replicas: 1  # Increase for HA\n    persistentVolume:\n      size: \"10Gi\"  # Adjust as needed\n    resources:\n      limits:\n        memory: \"2Gi\"\n        cpu: \"1000m\"\n\n  mimir:\n    structuredConfig:\n      limits:\n        compactor_blocks_retention_period: 30d  # Data retention\n</code></pre>"},{"location":"advanced/MIMIR_SETUP/#storage-backend","title":"Storage Backend","text":"<p>Default: Local filesystem (<code>/data/mimir</code>)</p> <p>To switch to S3/MinIO:</p> <pre><code>mimir:\n  mimir:\n    structuredConfig:\n      common:\n        storage:\n          backend: s3\n          s3:\n            endpoint: minio:9000\n            bucket_name: mimir-blocks\n            access_key_id: minioadmin\n            secret_access_key: minioadmin\n            insecure: true\n</code></pre>"},{"location":"advanced/MIMIR_SETUP/#enable-alertmanager","title":"Enable AlertManager","text":"<pre><code>mimir:\n  alertmanager:\n    enabled: true\n</code></pre>"},{"location":"advanced/MIMIR_SETUP/#architecture","title":"Architecture","text":""},{"location":"advanced/MIMIR_SETUP/#monolithic-vs-microservices","title":"Monolithic vs Microservices","text":"<p>Monolithic Mode (current setup): - One pod runs all components (distributor, ingester, querier, etc.) - Good for development and smaller production environments - Simpler to set up and debug</p> <p>Microservices Mode: - Each component runs separately - Better scalability for large production environments - Requires more resources and complexity</p>"},{"location":"advanced/MIMIR_SETUP/#components","title":"Components","text":"<p>Monolithic mode includes: - Distributor: Receives metrics from remote write - Ingester: Writes metrics to storage - Querier: Handles PromQL queries - Compactor: Compresses and retains blocks - Store Gateway: Reads from long-term storage - Nginx: Gateway/load balancer</p>"},{"location":"advanced/MIMIR_SETUP/#troubleshooting","title":"Troubleshooting","text":""},{"location":"advanced/MIMIR_SETUP/#pod-wont-start","title":"Pod Won't Start","text":"<pre><code># Check events\nkubectl describe pod mimir-0 -n observability-lab\n\n# Check logs\nkubectl logs mimir-0 -n observability-lab\n\n# Common issues:\n# - PVC binding (requires storageClass)\n# - Resource limits (increase memory/CPU)\n</code></pre>"},{"location":"advanced/MIMIR_SETUP/#no-data-in-grafana","title":"No Data in Grafana","text":"<pre><code># Verify Mimir endpoint\nkubectl exec -it -n observability-lab deploy/grafana -- \\\n  curl http://mimir-nginx/prometheus/api/v1/query?query=up\n\n# Check that remote_write works\nkubectl logs -n observability-lab mimir-0 | grep \"distributor\"\n</code></pre>"},{"location":"advanced/MIMIR_SETUP/#high-memory-usage","title":"High Memory Usage","text":"<p>Increase memory limits or reduce retention:</p> <pre><code>mimir:\n  monolithic:\n    resources:\n      limits:\n        memory: \"4Gi\"\n  mimir:\n    structuredConfig:\n      limits:\n        compactor_blocks_retention_period: 7d  # Kortare retention\n</code></pre>"},{"location":"advanced/MIMIR_SETUP/#comparison-with-prometheus","title":"Comparison with Prometheus","text":"Feature Prometheus Mimir Deployment Single binary Monolithic or microservices Storage Local TSDB S3/GCS/Azure/Filesystem Retention ~15 days (typical) Months/years HA Complex Built-in Scalability Limited Horizontal PromQL \u2705 \u2705 (compatible) Remote Write \u2705 \u2705"},{"location":"advanced/MIMIR_SETUP/#next-steps","title":"Next Steps","text":"<ol> <li>OpenTelemetry: Configure OTel Collector to send metrics to Mimir</li> <li>Multi-tenancy: Use <code>X-Scope-OrgId</code> headers for tenant isolation</li> <li>HA Setup: Increase replicas to 3 with zoneAwareReplication</li> <li>Production Storage: Migrate to S3/MinIO for persistence</li> </ol>"},{"location":"advanced/MIMIR_SETUP/#references","title":"References","text":"<ul> <li>NGDATA Mimir Fork</li> <li>Grafana Mimir Documentation</li> <li>Mimir Helm Chart</li> </ul>"},{"location":"guides/ARCHITECTURE/","title":"Architecture Guide","text":"<p>This document explains the design decisions and configuration patterns behind the ObservabilityStack.</p>"},{"location":"guides/ARCHITECTURE/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Architecture Guide</li> <li>Table of Contents</li> <li>Stack Configuration<ul> <li>Configuration Structure</li> </ul> </li> <li>Architecture Overview<ul> <li>Component Responsibilities</li> </ul> </li> <li>Helm Umbrella Chart Pattern<ul> <li>Umbrella Chart Structure</li> <li>How the Umbrella Pattern Works</li> <li>Multi-Values Configuration</li> <li>Understanding Subcharts</li> <li>How Subcharts Work</li> <li>Subchart Configuration Patterns</li> <li>Declarative Infrastructure (GitOps with ArgoCD)</li> <li>Adding New Components</li> </ul> </li> <li>Configuration Management<ul> <li>Editing Component Configuration</li> <li>Finding Configuration Options</li> </ul> </li> <li>Next Steps</li> </ul>"},{"location":"guides/ARCHITECTURE/#stack-configuration","title":"Stack Configuration","text":""},{"location":"guides/ARCHITECTURE/#configuration-structure","title":"Configuration Structure","text":"<ul> <li>Umbrella chart pattern - All components managed as subcharts</li> <li>GitOps deployment - Changes managed through Git commits</li> <li>Local filesystem storage - No external storage dependencies</li> </ul>"},{"location":"guides/ARCHITECTURE/#architecture-overview","title":"Architecture Overview","text":"<pre><code>flowchart TB\nsubgraph ObservabilityStack\n    subgraph External[External Access]\n        User[User Browser]\n    end\n\n    subgraph GitOps[GitOps and Deployment]\n        Git[Git Repository]\n        ArgoCD[ArgoCD Controller]\n        Helm[Helm Umbrella Chart]\n    end\n\n    subgraph Ingress[Ingress Layer]\n        Traefik[Traefik]\n    end\n\n    subgraph Pipeline[Telemetry Pipeline]\n        OTel[OTel Collector]\n    end\n\n    subgraph Backend[Storage Backends]\n        Loki[Loki - Logs]\n        Prometheus[Prometheus - Metrics]\n        Tempo[Tempo - Traces]\n    end\n\n    subgraph UI[Visualization]\n        Grafana[Grafana]\n    end\nend\n    %% GitOps Flow\n    Git --&gt;|Sync| ArgoCD\n    ArgoCD --&gt;|Deploy| Helm\n    Helm -.-&gt;|Install| Pipeline\n    Helm -.-&gt;|Install| Backend\n    Helm -.-&gt;|Install| UI\n    Helm -.-&gt;|Install| Ingress\n\n    %% Data Flow\n    OTel --&gt;|Logs| Loki\n    OTel --&gt;|Metrics| Prometheus\n    OTel --&gt;|Traces| Tempo\n\n    %% Query Flow\n    Grafana -.-&gt;|Query| Loki\n    Grafana -.-&gt;|Query| Prometheus\n    Grafana -.-&gt;|Query| Tempo\n\n    %% User Access\n    User --&gt;|HTTP| Traefik\n    Traefik --&gt;|Route| Grafana\n    Traefik --&gt;|Route| OTel\n\n    %% Styling\n    classDef gitops fill:#326CE5,stroke:#1558d6,color:#fff\n    classDef data fill:#F46800,stroke:#d45500,color:#fff\n    classDef storage fill:#00B3E6,stroke:#0099cc,color:#fff\n    classDef ui fill:#52C41A,stroke:#389e0d,color:#fff\n    classDef ingress fill:#722ED1,stroke:#531dab,color:#fff\n\n    class Git,ArgoCD,Helm gitops\n    class OTel data\n    class Loki,Prometheus,Tempo storage\n    class Grafana ui\n    class Traefik ingress</code></pre>"},{"location":"guides/ARCHITECTURE/#component-responsibilities","title":"Component Responsibilities","text":"Component Role Function ArgoCD GitOps Controller Syncs deployments from Git Traefik Ingress Controller Routes external traffic to services Loki Log Aggregation Stores and queries log data Tempo Trace Storage Stores distributed traces Prometheus Metrics Collection Collects and stores time-series metrics Grafana Visualization Provides dashboards for logs, metrics, and traces OTEL Collector Telemetry Pipeline Receives, processes, and routes telemetry data"},{"location":"guides/ARCHITECTURE/#helm-umbrella-chart-pattern","title":"Helm Umbrella Chart Pattern","text":""},{"location":"guides/ARCHITECTURE/#umbrella-chart-structure","title":"Umbrella Chart Structure","text":"<p>The <code>helm/stackcharts/</code> directory contains an umbrella chart that packages all components together:</p> <pre><code>helm/stackcharts/\n\u251c\u2500\u2500 Chart.yaml           # Umbrella chart definition\n\u251c\u2500\u2500 Chart.lock          # Dependency lock file  \n\u251c\u2500\u2500 values/             # Split configuration files (one per component)\n\u2502   \u251c\u2500\u2500 base.yaml           # Component enable/disable flags\n\u2502   \u251c\u2500\u2500 loki.yaml           # Loki configuration\n\u2502   \u251c\u2500\u2500 tempo.yaml          # Tempo configuration\n\u2502   \u251c\u2500\u2500 prometheus.yaml     # Prometheus configuration\n\u2502   \u251c\u2500\u2500 grafana.yaml        # Grafana configuration\n\u2502   \u251c\u2500\u2500 minio.yaml          # Minio configuration\n\u2502   \u2514\u2500\u2500 opentelemetry-collector.yaml  # OTel configuration\n\u2514\u2500\u2500 charts/             # Downloaded dependencies (.tgz files)\n    \u251c\u2500\u2500 grafana-10.0.0.tgz\n    \u251c\u2500\u2500 loki-6.36.0.tgz\n    \u251c\u2500\u2500 prometheus-27.30.0.tgz\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"guides/ARCHITECTURE/#how-the-umbrella-pattern-works","title":"How the Umbrella Pattern Works","text":"<p>With ArgoCD (Automated - Recommended) <pre><code># ArgoCD handles all value files automatically\nkubectl apply -f argocd/observability-stack.yaml -n argocd\n</code></pre> Single Deployment Command <pre><code># Deploy entire stack with one command\nhelm install observability-stack ./helm/stackcharts \\\n  -f helm/stackcharts/values/base.yaml \\\n  -f helm/stackcharts/values/loki.yaml \\\n  -f helm/stackcharts/values/tempo.yaml \\\n  -f helm/stackcharts/values/prometheus.yaml \\\n  -f helm/stackcharts/values/grafana.yaml \\\n  -f helm/stackcharts/values/minio.yaml \\\n  -f helm/stackcharts/values/opentelemetry-collector.yaml \\\n  -n observability-lab\n</code></pre> Version Management - <code>Chart.yaml</code> defines specific versions for all components - <code>Chart.lock</code> locks exact versions for reproducible deployments - <code>helm dependency update</code> downloads and packages all components</p> <p>Dependency Definition <pre><code># Chart.yaml automatically handles component relationships\ndependencies:\n  - name: grafana\n    version: \"10.0.0\"\n    repository: \"https://grafana.github.io/helm-charts\"\n    condition: grafana.enabled        # Controlled by values/base.yaml\n  - name: loki\n    version: \"6.36.0\" \n    repository: \"https://grafana.github.io/helm-charts\"\n    condition: loki.enabled           # Controlled by values/base.yaml\n</code></pre></p>"},{"location":"guides/ARCHITECTURE/#multi-values-configuration","title":"Multi-Values Configuration","text":"<p>Configuration is split into separate files for maintainability:</p> <p>Base Configuration (<code>values/base.yaml</code>) <pre><code># Controls which components are installed\nloki:\n  enabled: true\ntempo:\n  enabled: true\nprometheus:\n  enabled: true\ngrafana:\n  enabled: true\nminio:\n  enabled: false  # Disabled - using filesystem storage\nopentelemetry-collector:\n  enabled: true\n</code></pre></p> <p>Component Configuration (e.g., <code>values/grafana.yaml</code>) <pre><code># Grafana-specific settings\ngrafana:\n  fullnameOverride: grafana\n  replicas: 1\n  datasources:\n    datasources.yaml:\n      apiVersion: 1\n      datasources:\n        - name: Prometheus\n          type: prometheus\n          url: http://prometheus\n        - name: Loki\n          type: loki\n          url: http://loki-gateway\n  # ... more Grafana config\n</code></pre></p>"},{"location":"guides/ARCHITECTURE/#understanding-subcharts","title":"Understanding Subcharts","text":"<p>Each dependency becomes a subchart within the umbrella chart:</p> <pre><code>helm/stackcharts/\n\u251c\u2500\u2500 Chart.yaml              # Parent chart definition\n\u251c\u2500\u2500 values/                 # Split values files\n\u2502   \u251c\u2500\u2500 base.yaml              # Enable flags\n\u2502   \u251c\u2500\u2500 loki.yaml              # Loki config \u2192 loki subchart\n\u2502   \u251c\u2500\u2500 grafana.yaml           # Grafana config \u2192 grafana subchart\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 Chart.lock             # Locked subchart versions\n\u2514\u2500\u2500 charts/                # Downloaded subcharts\n    \u251c\u2500\u2500 grafana-10.0.0.tgz     # Subchart: Grafana\n    \u251c\u2500\u2500 loki-6.36.0.tgz        # Subchart: Loki  \n    \u251c\u2500\u2500 prometheus-27.30.0.tgz # Subchart: Prometheus\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"guides/ARCHITECTURE/#how-subcharts-work","title":"How Subcharts Work","text":"<p>Value Inheritance <pre><code># values/grafana.yaml - Passed to grafana subchart\ngrafana:                    # \u2190 Top-level key matches subchart name\n  adminPassword: secretpwd\n  datasources: [...]\n\n# values/loki.yaml - Passed to loki subchart\nloki:                      # \u2190 Top-level key matches subchart name\n  singleBinary:\n    replicas: 1\n\n# values/prometheus.yaml - Passed to prometheus subchart\nprometheus:                # \u2190 Top-level key matches subchart name\n  server:\n    persistentVolume:\n      size: 8Gi\n</code></pre></p> <p>How Helm Merges Values: 1. Helm reads all <code>-f</code> files in order (base.yaml first, then components) 2. Each file with matching top-level key (e.g., <code>loki:</code>) is merged 3. Later values override earlier ones 4. Final merged config is passed to each subchart</p> <p>Subchart Templates Each subchart has its own templates that get rendered: <pre><code>grafana subchart templates \u2192 grafana-deployment.yaml, grafana-service.yaml\nloki subchart templates    \u2192 loki-statefulset.yaml, loki-configmap.yaml  \nprometheus subchart templates \u2192 prometheus-deployment.yaml, etc.\n</code></pre></p> <p>Dependency Management <pre><code># Download/update all subcharts\nhelm dependency update helm/stackcharts/\n\n# This downloads:\n# - grafana-9.3.2.tgz from https://grafana.github.io/helm-charts  \n# - loki-6.36.0.tgz from https://grafana.github.io/helm-charts\n# - etc.\n</code></pre></p>"},{"location":"guides/ARCHITECTURE/#subchart-configuration-patterns","title":"Subchart Configuration Patterns","text":"<p>Global Values <pre><code># Shared across all subcharts\nglobal:\n  storageClass: \"local-path\"\n  imagePullSecrets: []\n\n# Each subchart can access global values\ngrafana:\n  # Uses global.storageClass automatically\n  persistence:\n    enabled: true\n\nloki:  \n  # Also uses global.storageClass\n  persistence:\n    enabled: true\n</code></pre></p> <p>Conditional Subcharts The <code>condition</code> field in <code>Chart.yaml</code> determines which subcharts are installed:</p> <pre><code># Chart.yaml - Defines the conditions\ndependencies:\n  - name: loki\n    version: \"6.36.0\" \n    repository: \"https://grafana.github.io/helm-charts\"\n    condition: loki.enabled        # \u2190 Controls if this subchart installs\n\n  - name: grafana\n    version: \"10.0.0\"\n    repository: \"https://grafana.github.io/helm-charts\" \n    condition: grafana.enabled     # \u2190 Controls if this subchart installs\n</code></pre> <pre><code># values/base.yaml - Sets the condition values\nloki:\n  enabled: true    # \u2190 This value is checked by \"condition: loki.enabled\"\n\ngrafana:\n  enabled: true    # \u2190 This value is checked by \"condition: grafana.enabled\"  \n\ntempo:\n  enabled: false   # \u2190 Setting to false will skip tempo installation\n</code></pre> <p>How It Works: - Helm checks <code>values/base.yaml</code> for the condition path (e.g., <code>loki.enabled</code>) - If <code>true</code>, the subchart is included in deployment - If <code>false</code> or missing, the subchart is skipped entirely - This allows selective component installation from the same umbrella chart</p> <p>Practical Examples: <pre><code># Deploy only logs and visualization (no metrics or tracing)\n# In values/base.yaml:\nloki:\n  enabled: true\ngrafana: \n  enabled: true\nprometheus:\n  enabled: false   # Skip metrics collection\ntempo:\n  enabled: false   # Skip tracing\nopentelemetry-collector:\n  enabled: true    # Keep collector for log processing\n</code></pre></p> <p>Cross-Subchart References <pre><code># Grafana subchart references other subcharts\ngrafana:\n  datasources:\n    datasources.yaml:\n      datasources:\n      - name: Prometheus\n        # Reference to prometheus subchart service\n        url: http://{{ include \"prometheus.fullname\" . }}:{{ .Values.prometheus.server.service.port }}\n      - name: Loki  \n        # Reference to loki subchart service\n        url: http://{{ include \"loki.serviceName\" . }}:{{ .Values.loki.service.port }}\n</code></pre></p>"},{"location":"guides/ARCHITECTURE/#declarative-infrastructure-gitops-with-argocd","title":"Declarative Infrastructure (GitOps with ArgoCD)","text":"<p>ArgoCD Application Configuration: <pre><code># argocd/observability-stack.yaml\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: observability-stack\nspec:\n  source:\n    repoURL: 'https://github.com/fiddeb/observabilitystack.git'\n    path: helm/stackcharts        # Points to umbrella chart\n    targetRevision: main          # Tracks main branch\n    helm:\n      valueFiles:                 # Multi-values configuration\n        - values/base.yaml\n        - values/loki.yaml\n        - values/tempo.yaml\n        - values/prometheus.yaml\n        - values/grafana.yaml\n        - values/minio.yaml\n        - values/opentelemetry-collector.yaml\n</code></pre></p> <p>Change Workflow: 1. Edit the relevant values file (e.g., <code>values/grafana.yaml</code>) 2. Commit: <code>git add helm/stackcharts/values/grafana.yaml &amp;&amp; git commit -m \"feat: update grafana\"</code> 3. Push: <code>git push</code> 4. ArgoCD auto-syncs (or force it with <code>./scripts/force_argo_sync.sh</code>) 5. Check the changes in ArgoCD UI: http://argocd.k8s.test</p>"},{"location":"guides/ARCHITECTURE/#adding-new-components","title":"Adding New Components","text":"<p>To add a new component (e.g., Jaeger for tracing):</p> <p>1. Add to Chart.yaml dependencies: <pre><code># helm/stackcharts/Chart.yaml\ndependencies:\n  - name: jaeger\n    version: \"0.71.2\"\n    repository: https://jaegertracing.github.io/helm-charts\n    condition: jaeger.enabled\n</code></pre></p> <p>2. Create values file: <pre><code># helm/stackcharts/values/jaeger.yaml\njaeger:\n  fullnameOverride: jaeger\n  # ... jaeger configuration\n</code></pre></p> <p>3. Add enable flag: <pre><code># helm/stackcharts/values/base.yaml\njaeger:\n  enabled: true\n</code></pre></p> <p>4. Update ArgoCD Application: <pre><code># argocd/observability-stack.yaml\nspec:\n  source:\n    helm:\n      valueFiles:\n        - values/base.yaml\n        # ... existing files\n        - values/jaeger.yaml    # Add new file\n</code></pre></p> <p>5. Update dependencies and commit: <pre><code>helm dependency update helm/stackcharts/\ngit add helm/stackcharts/\ngit commit -m \"feat: add Jaeger tracing\"\ngit push\n</code></pre></p>"},{"location":"guides/ARCHITECTURE/#configuration-management","title":"Configuration Management","text":""},{"location":"guides/ARCHITECTURE/#editing-component-configuration","title":"Editing Component Configuration","text":"<p>Each component has its own values file in <code>helm/stackcharts/values/</code>:</p> <p>Example: Updating Grafana datasources</p> <ol> <li> <p>Edit the component file: <pre><code>vim helm/stackcharts/values/grafana.yaml\n</code></pre></p> </li> <li> <p>Make your changes: <pre><code>grafana:\n  datasources:\n    datasources.yaml:\n      apiVersion: 1\n      datasources:\n      - name: Prometheus\n        type: prometheus\n        url: http://prometheus\n      - name: NewDatasource  # Add new datasource\n        type: influxdb\n        url: http://influxdb:8086\n</code></pre></p> </li> <li> <p>Commit and push: <pre><code>git add helm/stackcharts/values/grafana.yaml\ngit commit -m \"feat: add InfluxDB datasource to Grafana\"\ngit push\n</code></pre></p> </li> <li> <p>ArgoCD syncs automatically (or force: <code>./scripts/force_argo_sync.sh</code>)</p> </li> </ol> <p>Commit and push - ArgoCD will remove Tempo resources automatically.</p>"},{"location":"guides/ARCHITECTURE/#finding-configuration-options","title":"Finding Configuration Options","text":"<p>Each component has configuration options:</p> <ol> <li> <p>Check component values file: <pre><code># See all Loki options\ncat helm/stackcharts/values/loki.yaml\n</code></pre></p> </li> <li> <p>Check upstream chart documentation:</p> </li> <li>Grafana: https://github.com/grafana/helm-charts/tree/main/charts/grafana</li> <li>Loki: https://github.com/grafana/helm-charts/tree/main/charts/loki</li> <li>Tempo: https://github.com/grafana/helm-charts/tree/main/charts/tempo</li> <li> <p>Prometheus: https://github.com/prometheus-community/helm-charts/tree/main/charts/prometheus</p> </li> <li> <p>Extract default values from charts: <pre><code>helm show values grafana/grafana &gt; /tmp/grafana-defaults.yaml\nhelm show values grafana/loki &gt; /tmp/loki-defaults.yaml\n</code></pre></p> </li> </ol>"},{"location":"guides/ARCHITECTURE/#next-steps","title":"Next Steps","text":"<p>After understanding this:</p> <ol> <li>Setup: Installation Guide</li> <li>Try it: Usage Guide for hands-on practice</li> <li>Customize: Edit files in <code>helm/stackcharts/values/</code> for your needs</li> <li>Debug: Troubleshooting Guide when things break</li> </ol>"},{"location":"guides/GIT_WORKFLOW/","title":"Git Workflow and ArgoCD Branch Management","text":"<p>How to make sure <code>targetRevision</code> points to <code>main</code> before merging.</p>"},{"location":"guides/GIT_WORKFLOW/#the-problem","title":"The Problem","text":"<p>When working with feature branches, <code>targetRevision</code> in the ArgoCD manifest gets updated to point to your feature branch. You need to reset it to <code>main</code> before merging, otherwise production breaks.</p>"},{"location":"guides/GIT_WORKFLOW/#solutions","title":"Solutions","text":""},{"location":"guides/GIT_WORKFLOW/#1-automatic-merge-script","title":"1. Automatic Merge Script","text":"<p>Use <code>scripts/merge_feature.sh</code> to automatically handle the entire merge process:</p> <pre><code># Example: Merge feat/loki-s3-storage to main\n./scripts/merge_feature.sh feat/loki-s3-storage\n</code></pre> <p>The script automatically: 1. Commits any changes on the feature branch 2. Resets <code>targetRevision</code> to <code>main</code> 3. Switches to main branch and updates from remote 4. Merges the feature branch 5. Offers to delete the feature branch</p>"},{"location":"guides/GIT_WORKFLOW/#2-git-pre-merge-hook","title":"2. Git Pre-Merge Hook","text":"<p>A Git hook in <code>.git/hooks/pre-merge-commit</code> automatically checks that <code>targetRevision</code> is <code>main</code> before merge:</p> <pre><code># The hook activates automatically during merge\ngit merge feat/my-feature\n# If targetRevision is not 'main', merge is aborted with error message\n</code></pre>"},{"location":"guides/GIT_WORKFLOW/#3-manual-check","title":"3. Manual Check","text":"<p>If you merge manually, always check <code>targetRevision</code> first:</p> <pre><code># Check current targetRevision\ngrep \"targetRevision:\" argocd/observability-stack.yaml\n\n# Reset to main if necessary\nsed -i 's|targetRevision: .*|targetRevision: main   # auto-synced with current branch|g' argocd/observability-stack.yaml\ngit add argocd/observability-stack.yaml\ngit commit -m \"fix: reset targetRevision to main before merge\"\n</code></pre>"},{"location":"guides/GIT_WORKFLOW/#4-force-argocd-sync-warnings","title":"4. Force ArgoCD Sync Warnings","text":"<p><code>scripts/force_argo_sync.sh</code> now shows warnings when you're not on the main branch:</p> <pre><code>./scripts/force_argo_sync.sh\n# \u26a0\ufe0f  WARNING: You are on branch 'feat/my-feature', not 'main'\n# \ud83d\udca1 Consider using main branch for production deployments\n</code></pre>"},{"location":"guides/GIT_WORKFLOW/#how-to-work-with-feature-branches","title":"How to Work with Feature Branches","text":"<ol> <li> <p>Create feature branch: <pre><code>git checkout -b feat/my-new-feature\n</code></pre></p> </li> <li> <p>Develop and test: <pre><code># Make changes\ngit add .\ngit commit -m \"feat: implement new feature\"\n\n# Test with ArgoCD\n./scripts/force_argo_sync.sh\n</code></pre></p> </li> <li> <p>Merge to main: <pre><code># Use automatic merge script\n./scripts/merge_feature.sh feat/my-new-feature\n\n# Or manually (with Git hook protection)\ngit checkout main\ngit merge feat/my-new-feature\n</code></pre></p> </li> <li> <p>Deploy from main: <pre><code>git push origin main\n./scripts/force_argo_sync.sh\n</code></pre></p> </li> </ol>"},{"location":"guides/GIT_WORKFLOW/#safety-features","title":"Safety Features","text":"<ul> <li>Git Hook: Blocks merge if <code>targetRevision</code> isn't <code>main</code></li> <li>Merge Script: Auto-resets before merge</li> <li>Sync Script: Warns when you're not on main</li> <li>Backup: <code>.bak</code> files created during auto-changes</li> </ul>"},{"location":"guides/GIT_WORKFLOW/#troubleshooting","title":"Troubleshooting","text":"<p>If merge is aborted by Git hook: <pre><code># Reset targetRevision manually\nsed -i 's|targetRevision: .*|targetRevision: main   # auto-synced with current branch|g' argocd/observability-stack.yaml\ngit add argocd/observability-stack.yaml\ngit commit -m \"fix: reset targetRevision to main before merge\"\n\n# Try merge again\ngit merge feat/my-feature\n</code></pre></p>"},{"location":"guides/INSTALLATION/","title":"Installation Guide","text":"<p>How to install the ObservabilityStack - a development and learning environment.</p> <p>New to the Stack? Read the Architecture Guide first to understand the design decisions and configuration patterns.</p> <p>Lab Environment: This is for local development, learning, and experimentation. It uses simplified configurations and default credentials that aren't suitable for production.</p>"},{"location":"guides/INSTALLATION/#what-youll-get","title":"What You'll Get","text":"<p>An observability lab with: - Quick Setup: One command installs everything - The basics: Logs, metrics, traces, and visualization - GitOps: ArgoCD manages deployments</p>"},{"location":"guides/INSTALLATION/#prerequisites","title":"Prerequisites","text":""},{"location":"guides/INSTALLATION/#1-kubernetes-cluster","title":"1. Kubernetes Cluster","text":"<p>Ensure you have a running Kubernetes cluster with <code>kubectl</code> configured: - Rancher Desktop (good for local development) - Minikube  - k3s/k3d (lightweight)</p>"},{"location":"guides/INSTALLATION/#2-ingress-controller","title":"2. Ingress Controller","text":"<p>Install Traefik as the ingress controller:</p> <pre><code># Add Traefik helm repository\nhelm repo add traefik https://helm.traefik.io/traefik\nhelm repo update\n\n# Install Traefik\nhelm install traefik traefik/traefik\n</code></pre>"},{"location":"guides/INSTALLATION/#3-dns-configuration-for-local-access","title":"3. DNS Configuration for Local Access","text":"<p>To access services via URLs like <code>grafana.k8s.test</code>, set up local DNS.</p>"},{"location":"guides/INSTALLATION/#option-1-static-hosts-file-simple","title":"Option 1: Static Hosts File (Simple)","text":"<p>Add these entries to your <code>/etc/hosts</code> file:</p> <pre><code># Add to /etc/hosts\n127.0.0.1 grafana.k8s.test\n127.0.0.1 loki.k8s.test  \n127.0.0.1 tempo.k8s.test\n127.0.0.1 prometheus.k8s.test\n127.0.0.1 otel-collector.k8s.test\n127.0.0.1 argocd.k8s.test\n</code></pre>"},{"location":"guides/INSTALLATION/#option-2-dnsmasq-recommended-for-labs","title":"Option 2: dnsmasq (Recommended for Labs)","text":"<p>Set up wildcard DNS resolution for <code>*.k8s.test</code> domains:</p>"},{"location":"guides/INSTALLATION/#macos-setup","title":"macOS Setup","text":"<pre><code># Install dnsmasq (macOS with Homebrew)\nbrew install dnsmasq\n\n# Configure dnsmasq for wildcard resolution\necho \"listen-address=127.0.0.1\" &gt;&gt; /opt/homebrew/etc/dnsmasq.conf\necho \"bind-interfaces\" &gt;&gt; /opt/homebrew/etc/dnsmasq.conf  \necho \"address=/.k8s.test/127.0.0.1\" &gt;&gt; /opt/homebrew/etc/dnsmasq.conf\n\n# Setup system resolver\nsudo mkdir -p /etc/resolver\necho \"nameserver 127.0.0.1\" | sudo tee /etc/resolver/k8s.test\n\n# Start dnsmasq\nsudo brew services start dnsmasq\n\n# Verify DNS resolution\ndig grafana.k8s.test @127.0.0.1\n</code></pre>"},{"location":"guides/INSTALLATION/#linux-setup","title":"Linux Setup","text":"<p>Ubuntu/Debian: <pre><code># Install dnsmasq\nsudo apt-get update\nsudo apt-get install -y dnsmasq\n\n# Configure dnsmasq for wildcard resolution\necho \"listen-address=127.0.0.1\" | sudo tee -a /etc/dnsmasq.conf\necho \"bind-interfaces\" | sudo tee -a /etc/dnsmasq.conf\necho \"address=/.k8s.test/127.0.0.1\" | sudo tee -a /etc/dnsmasq.conf\n\n# Configure NetworkManager to use dnsmasq\necho -e \"[main]\\ndns=dnsmasq\" | sudo tee /etc/NetworkManager/conf.d/dnsmasq.conf\n\n# Restart services\nsudo systemctl restart dnsmasq\nsudo systemctl restart NetworkManager\n\n# Verify DNS resolution\ndig grafana.k8s.test @127.0.0.1\n</code></pre></p> <p>Fedora/RHEL/CentOS: <pre><code># Install dnsmasq\nsudo dnf install -y dnsmasq  # or: sudo yum install -y dnsmasq\n\n# Configure dnsmasq for wildcard resolution\necho \"listen-address=127.0.0.1\" | sudo tee -a /etc/dnsmasq.conf\necho \"bind-interfaces\" | sudo tee -a /etc/dnsmasq.conf\necho \"address=/.k8s.test/127.0.0.1\" | sudo tee -a /etc/dnsmasq.conf\n\n# Configure NetworkManager to use dnsmasq\necho -e \"[main]\\ndns=dnsmasq\" | sudo tee /etc/NetworkManager/conf.d/dnsmasq.conf\n\n# Restart services\nsudo systemctl restart dnsmasq\nsudo systemctl restart NetworkManager\n\n# Verify DNS resolution\ndig grafana.k8s.test @127.0.0.1\n</code></pre></p>"},{"location":"guides/INSTALLATION/#windows-setup","title":"Windows Setup","text":"<p>Windows users: Use Option 1 (static hosts file) at <code>C:\\Windows\\System32\\drivers\\etc\\hosts</code> (requires admin privileges). Wildcard DNS setup on Windows requires more complex configurations beyond the scope of this lab.</p>"},{"location":"guides/INSTALLATION/#option-3-no-dns-port-forwarding-only","title":"Option 3: No DNS (Port Forwarding Only)","text":"<p>If you prefer not to configure DNS, you can access everything via port forwarding (see Troubleshooting section).</p>"},{"location":"guides/INSTALLATION/#4-resource-requirements","title":"4. Resource Requirements","text":"<p>Minimum Requirements: - CPU: 2 cores (recommended: 4 cores) - Memory: 4GB RAM (recommended: 8GB RAM) - Storage: 10GB available disk space</p>"},{"location":"guides/INSTALLATION/#installation","title":"Installation","text":""},{"location":"guides/INSTALLATION/#fork-the-repository-recommended","title":"Fork the Repository (Recommended)","text":"<p>If you plan to experiment or customize, fork this first:</p> <ol> <li>Fork on GitHub:</li> <li>Go to https://github.com/fiddeb/observabilitystack</li> <li>Click \"Fork\" in the top-right</li> <li> <p>This creates your own copy to modify</p> </li> <li> <p>Clone your fork (replace <code>YOUR_USERNAME</code> with your GitHub username):    <pre><code>git clone https://github.com/YOUR_USERNAME/observabilitystack.git\ncd observabilitystack\n</code></pre></p> </li> <li> <p>Add upstream remote (to get updates):    <pre><code>git remote add upstream https://github.com/fiddeb/observabilitystack.git\n</code></pre></p> </li> </ol> <p>Why fork? - Customize for your needs - Experiment without affecting the original - Create pull requests to contribute - GitOps: ArgoCD can watch your fork</p>"},{"location":"guides/INSTALLATION/#quick-lab-setup","title":"Quick Lab Setup","text":"<p>The simplest way to get your observability lab running:</p> <pre><code># Clone the repository (or your fork - see above)\ngit clone https://github.com/fiddeb/observabilitystack.git\ncd observabilitystack\n\n# Setup ArgoCD application (automatically detects your repository)\n./scripts/setup_argocd.sh\n\n# One-command installation\n./scripts/install_argo.sh\n</code></pre> <p>What happens: 1. Updates Helm chart dependencies 2. Installs ArgoCD 3. Configures ArgoCD for HTTP access 4. Installs ArgoCD ingress 5. Deploys the observability stack 6. Sets up local filesystem storage</p> <p>After installation, access ArgoCD at: - URL: http://argocd.k8s.test - Username: admin - Password: <code>kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d</code></p>"},{"location":"guides/INSTALLATION/#argocd-management-interface","title":"ArgoCD Management Interface","text":"<p>ArgoCD provides a web interface to monitor and manage your deployments.</p>"},{"location":"guides/INSTALLATION/#access-argocd-web-ui","title":"Access ArgoCD Web UI","text":"<p>ArgoCD ingress is automatically installed and configured during setup.</p>"},{"location":"guides/INSTALLATION/#primary-access-recommended","title":"Primary Access (Recommended)","text":"<pre><code># Access ArgoCD via ingress\nopen http://argocd.k8s.test\n\n# Get admin password\nkubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d &amp;&amp; echo\n</code></pre> <p>Login credentials: - Username: admin - Password: (from command above)</p>"},{"location":"guides/INSTALLATION/#backup-access-port-forwarding","title":"Backup Access (Port Forwarding)","text":"<p>If DNS/ingress doesn't work, use port forwarding:</p> <pre><code># Forward ArgoCD server to local port\nkubectl port-forward svc/argocd-server -n argocd 8080:80 &amp;\n\n# Access: http://localhost:8080\n# Username: admin\n# Password: (same as above)\n</code></pre>"},{"location":"guides/INSTALLATION/#get-argocd-credentials","title":"Get ArgoCD Credentials","text":"<pre><code># Username is always: admin\n\n# Get password\nkubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d &amp;&amp; echo\n\n# Optional: Change admin password via CLI\nargocd account update-password --current-password &lt;current-admin-password&gt; --new-password &lt;new-password&gt;\n</code></pre>"},{"location":"guides/INSTALLATION/#using-your-fork-with-argocd","title":"Using Your Fork with ArgoCD","text":"<p>If you forked the repository, the setup automatically detects your repository URL:</p> <pre><code># Setup ArgoCD application with correct repository (automatically detects fork)\n./scripts/setup_argocd.sh\n</code></pre> <p>What this script does: - Automatically detects your git remote URL (original repo or fork) - Updates the ArgoCD application manifest with the correct <code>repoURL</code> - Applies the configuration to your cluster - Works with both HTTPS and SSH git URLs</p> <p>When to run this script: - Before installing ArgoCD - Sets up the correct repository URL from the start - After forking - Updates the configuration to use your fork instead of the original - When switching between repositories - If you change your git remote URL - After cloning a different fork - Automatically adapts to the new repository</p> <p>How to run: <pre><code># From project root directory (recommended)\n./scripts/setup_argocd.sh\n\n# Or from any directory within the project\ncd scripts &amp;&amp; ./setup_argocd.sh\ncd /path/to/project &amp;&amp; ./scripts/setup_argocd.sh\n</code></pre></p> <p>Prerequisites: - Must be run from within the git repository - Git remote 'origin' must be configured - kubectl access to your cluster (optional - for automatic application)</p> <p>Manual method (if you prefer to edit manually): <pre><code># Edit the ArgoCD application manifest\nvim argocd/observability-stack.yaml\n\n# Change the repoURL to your fork:\n# spec:\n#   source:\n#     repoURL: https://github.com/YOUR_USERNAME/observabilitystack.git\n\n# Apply the updated application\nkubectl apply -f argocd/observability-stack.yaml -n argocd\n</code></pre></p> <p>This allows ArgoCD to automatically sync changes from your fork when you push updates.</p>"},{"location":"guides/INSTALLATION/#manual-argocd-setup","title":"Manual ArgoCD Setup","text":"<p>If you prefer manual setup:</p> <pre><code># Update Helm dependencies first\ncd helm/stackcharts\nhelm dependency update\ncd ../..\n\n# Install ArgoCD\nkubectl create namespace argocd\nkubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml\n\n# Create the observability application (use your fork if you have one)\nkubectl apply -f argocd/observability-stack.yaml -n argocd\n</code></pre>"},{"location":"guides/INSTALLATION/#updating-helm-dependencies","title":"Updating Helm Dependencies","text":"<p>If you need to update chart dependencies manually:</p> <pre><code>cd helm/stackcharts\nhelm dependency update\n</code></pre> <p>This downloads the required Helm charts specified in <code>Chart.yaml</code>: - Grafana, Loki, Tempo, Prometheus - OpenTelemetry Collector</p> <p>The downloaded charts are saved in <code>charts/</code> directory and committed to the repository for reproducible builds.</p>"},{"location":"guides/INSTALLATION/#lab-components","title":"Lab Components","text":"<p>The installation deploys an observability stack:</p> <ul> <li>OpenTelemetry Collector - Telemetry ingestion</li> <li>Loki - Log storage (local filesystem)</li> <li>Tempo - Trace storage (local filesystem) </li> <li>Prometheus - Metrics storage</li> <li>Grafana - Visualization (pre-configured datasources)</li> </ul> <p>Lab Features: - No login required for Grafana - Pre-configured data sources - Local filesystem storage</p>"},{"location":"guides/INSTALLATION/#verification","title":"Verification","text":""},{"location":"guides/INSTALLATION/#check-deployment-status","title":"Check Deployment Status","text":"<pre><code># Verify all pods are running\nkubectl get pods -n observability-lab\n\n# Check ArgoCD application status\nkubectl get application observability-stack -n argocd\n</code></pre>"},{"location":"guides/INSTALLATION/#access-your-lab-environment","title":"Access Your Lab Environment","text":"<p>After installation, your observability lab is available at:</p> <ul> <li>Grafana (Main Dashboard): http://grafana.k8s.test </li> <li>Credentials: No credentials needed (disable_login: false to use default admin/admin)</li> <li>Features: Pre-configured datasources with multi-tenant support for logs</li> <li>Data Sources: Prometheus, Loki (foo tenant), Loki (bazz tenant), Tempo</li> <li>ArgoCD (GitOps Management): http://argocd.k8s.test</li> <li>Username: admin</li> <li>Password: <code>kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d</code></li> <li>Features: Monitor deployments, sync applications, view Git integration</li> <li>Prometheus (Metrics): http://prometheus.k8s.test  </li> <li>Loki (Logs): http://loki.k8s.test</li> <li>Tempo (Traces): http://tempo.k8s.test</li> <li>OpenTelemetry Collector: http://otel-collector.k8s.test</li> </ul> <p>First Visit: Start with Grafana to explore the pre-configured dashboards, then check ArgoCD to see how GitOps deployment works</p>"},{"location":"guides/INSTALLATION/#test-your-lab-setup","title":"Test Your Lab Setup","text":"<p>Verify everything works with built-in tests:</p> <pre><code># Run automated test suite\nkubectl apply -f manifests/telemetry-test-jobs.yaml\n\n# Wait for tests to complete (~30 seconds)\nkubectl wait --for=condition=complete job/telemetrygen-metrics -n observability-lab --timeout=60s\nkubectl wait --for=condition=complete job/telemetrygen-logs -n observability-lab --timeout=60s\nkubectl wait --for=condition=complete job/telemetrygen-traces -n observability-lab --timeout=60s\n</code></pre>"},{"location":"guides/INSTALLATION/#verify-in-grafana","title":"Verify in Grafana","text":"<p>Open Grafana and check: - Metrics: Explore \u2192 Prometheus \u2192 <code>gen{}</code> - Logs (foo tenant): Explore \u2192 Loki \u2192 <code>{job=\"telemetrygen\"}</code> - Logs (bazz tenant): Explore \u2192 Loki-bazz \u2192 <code>{job=\"audit-logs\"}</code>  - Traces: Explore \u2192 Tempo \u2192 <code>{service.name=\"telemetrygen\"}</code></p> <p>Multi-Tenant Testing: Test both Loki datasources in Grafana to see tenant isolation in action. Send logs with <code>dev.audit.category</code> attribute to see automatic routing to the bazz tenant.</p>"},{"location":"guides/INSTALLATION/#troubleshooting-lab-setup","title":"Troubleshooting Lab Setup","text":""},{"location":"guides/INSTALLATION/#repository-setup-issues","title":"Repository Setup Issues","text":"<p>ArgoCD not updating? <pre><code># Force refresh in ArgoCD UI or CLI\nkubectl patch app observability-stack -n argocd --type merge -p '{\"metadata\":{\"annotations\":{\"argocd.argoproj.io/refresh\":\"hard\"}}}'\n\n# Or delete and recreate\nkubectl delete app observability-stack -n argocd\n./scripts/setup_argocd.sh\n</code></pre></p>"},{"location":"guides/INSTALLATION/#dns-not-working","title":"DNS Not Working?","text":"<p>Option 1 - Port Forwarding (Always Works) <pre><code># Access via localhost ports\nkubectl port-forward service/grafana 3000:3000 -n observability-lab &amp;\nkubectl port-forward service/loki 3100:3100 -n observability-lab &amp;\nkubectl port-forward service/prometheus 9090:9090 -n observability-lab &amp;\nkubectl port-forward svc/argocd-server -n argocd 8080:443 &amp;\n\n# Then open:\n# - Grafana: http://localhost:3000\n# - Loki: http://localhost:3100  \n# - Prometheus: http://localhost:9090\n# - ArgoCD: https://localhost:8080\n</code></pre></p> <p>Option 2 - Check DNS <pre><code># Test DNS resolution\nnslookup grafana.k8s.test\n\n# If using dnsmasq, restart it\nsudo brew services restart dnsmasq\n\n# If using /etc/hosts, verify entries\ncat /etc/hosts | grep k8s.test\n</code></pre></p>"},{"location":"guides/INSTALLATION/#pods-not-starting","title":"Pods Not Starting?","text":"<pre><code># Quick health check\n./scripts/force_argo_sync.sh\n\n# Check pod status\nkubectl get pods -n observability-lab\n\n# Check events for errors\nkubectl get events -n observability-lab --sort-by=.metadata.creationTimestamp | tail -10\n</code></pre>"},{"location":"guides/INSTALLATION/#need-more-help","title":"Need More Help?","text":"<ul> <li>Troubleshooting Guide - Full debugging reference</li> </ul>"},{"location":"guides/INSTALLATION/#next-steps","title":"Next Steps","text":""},{"location":"guides/INSTALLATION/#understand-the-architecture","title":"Understand the Architecture","text":"<ul> <li>Architecture Guide - Why the stack is built this way and how to customize it</li> </ul>"},{"location":"guides/INSTALLATION/#send-custom-data","title":"Send Custom Data","text":"<ul> <li>Follow Usage Guide to send your own logs, metrics, and traces</li> <li>Use the OpenTelemetry Collector endpoints</li> </ul>"},{"location":"guides/INSTALLATION/#customize-your-setup","title":"Customize Your Setup","text":"<ul> <li>See Architecture Guide - Configuration Management for configuration patterns</li> <li>Learn about the single <code>values.yaml</code> approach and multi-tenant setup</li> </ul>"},{"location":"guides/INSTALLATION/#learning-resources","title":"Learning Resources","text":"<ul> <li>Usage Guide - How to use the stack</li> <li>Git Workflow - How to make changes safely</li> <li>OpenTelemetry Documentation - https://opentelemetry.io/docs/</li> </ul>"},{"location":"guides/TROUBLESHOOTING/","title":"Troubleshooting Guide","text":"<p>How to debug, test, and recover the ObservabilityStack.</p>"},{"location":"guides/TROUBLESHOOTING/#quick-recovery","title":"Quick Recovery","text":""},{"location":"guides/TROUBLESHOOTING/#5-minute-health-check","title":"5-Minute Health Check","text":"<pre><code># 1. Pod status\nkubectl get pods -n observability-lab\n\n# 2. ArgoCD sync status\nkubectl get application observability-stack -n argocd\n\n# 3. Endpoint connectivity\ncurl -s http://loki.k8s.test/ready\ncurl -s http://grafana.k8s.test/api/health\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#common-fixes","title":"Common Fixes","text":""},{"location":"guides/TROUBLESHOOTING/#if-pods-are-down","title":"If Pods Are Down","text":"<pre><code># 1. Check recent events\nkubectl get events -n observability-lab --sort-by=.metadata.creationTimestamp | tail -10\n\n# 2. Restart problematic pod\nkubectl delete pod &lt;pod-name&gt; -n observability-lab\n\n# 3. Force ArgoCD sync\n./scripts/force_argo_sync.sh\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#if-ingress-doesnt-work","title":"If Ingress Doesn't Work","text":"<pre><code># 1. Use port forwards as backup\nkubectl port-forward service/grafana 3000:80 -n observability-lab &amp;\nkubectl port-forward service/loki 3100:3100 -n observability-lab &amp;\n\n# 2. Test service directly\nkubectl run -it --rm debug --image=curlimages/curl --restart=Never -- \\\n  curl -s http://loki.observability-lab.svc.cluster.local:3100/ready\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#restart-all-pods","title":"Restart All Pods","text":"<pre><code># 1. Delete all pods (Kubernetes recreates them)\nkubectl delete pods --all -n observability-lab\n\n# 2. Wait for all pods to be ready\nkubectl get pods -n observability-lab -w\n\n# 3. Verify health and sync\n./scripts/force_argo_sync.sh\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#argocd-recovery","title":"ArgoCD Recovery","text":"<pre><code># 1. Reset to known good state\ngit checkout main\n./scripts/force_argo_sync.sh\n\n# 2. If that fails, recreate application\nkubectl delete application observability-stack -n argocd\nkubectl apply -f argocd/observability-stack.yaml -n argocd\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#one-liner-status-check","title":"One-Liner Status Check","text":"<pre><code>echo \"=== Pods ===\" &amp;&amp; kubectl get pods -n observability-lab &amp;&amp; \\\necho \"=== ArgoCD ===\" &amp;&amp; kubectl get application observability-stack -n argocd &amp;&amp; \\\necho \"=== Endpoints ===\" &amp;&amp; curl -s http://loki.k8s.test/ready &amp;&amp; \\\ncurl -sI http://grafana.k8s.test | head -1\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#deployment-checklists","title":"Deployment Checklists","text":""},{"location":"guides/TROUBLESHOOTING/#pre-deployment-checklist","title":"Pre-Deployment Checklist","text":"<ul> <li>[ ] <code>git status</code> - No uncommitted changes</li> <li>[ ] <code>targetRevision: main</code> in <code>argocd/observability-stack.yaml</code></li> <li>[ ] All tests pass locally</li> <li>[ ] Configuration reviewed</li> </ul>"},{"location":"guides/TROUBLESHOOTING/#post-deployment-checklist","title":"Post-Deployment Checklist","text":"<ul> <li>[ ] All pods Running: <code>kubectl get pods -n observability-lab</code></li> <li>[ ] ArgoCD Synced + Healthy: <code>kubectl get application observability-stack -n argocd</code></li> <li>[ ] Ingress endpoints respond: <code>loki.k8s.test</code>, <code>grafana.k8s.test</code></li> <li>[ ] Test log ingestion (see Loki Testing)</li> </ul>"},{"location":"guides/TROUBLESHOOTING/#deployment-verification","title":"Deployment Verification","text":"<pre><code># Pod status\nkubectl get pods -n observability-lab\n\n# ArgoCD status\nkubectl get application observability-stack -n argocd\n\n# Service endpoints\ncurl -s http://loki.k8s.test/ready\ncurl -s http://grafana.k8s.test/api/health\n\n# Test log ingestion\ncurl -H \"Content-Type: application/json\" -H \"X-Scope-OrgID: foo\" \\\n  -XPOST \"http://loki.k8s.test/loki/api/v1/push\" \\\n  -d '{\"streams\":[{\"stream\":{\"job\":\"deployment-test\"},\"values\":[[\"'$(date +%s%N)'\",\"Deployment verification\"]]}]}'\n\n# Verify log arrived\nlogcli query --addr=http://loki.k8s.test --org-id=\"foo\" \\\n  '{job=\"deployment-test\"}' --limit=5 --since=5m\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#git-and-branch-management","title":"Git and Branch Management","text":""},{"location":"guides/TROUBLESHOOTING/#branch-information","title":"Branch Information","text":"<pre><code># Current branch\ngit rev-parse --abbrev-ref HEAD\n\n# All branches\ngit branch -a\n\n# Status and changes\ngit status\ngit diff\ngit diff --cached\n\n# Commit history\ngit log --oneline -10\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#feature-branch-workflow","title":"Feature Branch Workflow","text":"<pre><code># Create feature branch\ngit checkout -b feat/my-feature\n\n# Commit changes\ngit add -u  # For modified files\ngit add &lt;filename&gt;  # For new files\ngit commit -m \"feat: description of change\"\n\n# Merge to main (recommended - uses script)\n./scripts/merge_feature.sh feat/my-feature\n\n# Manual merge (with Git hook protection)\ngit checkout main\ngit merge feat/my-feature\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#argocd-operations","title":"ArgoCD Operations","text":""},{"location":"guides/TROUBLESHOOTING/#application-status","title":"Application Status","text":"<pre><code># List all applications\nkubectl get applications -n argocd\n\n# Detailed status\nkubectl get application observability-stack -n argocd -o yaml\n\n# Check targetRevision (should match current Git branch)\nkubectl get application observability-stack -n argocd \\\n  -o jsonpath='{.spec.source.targetRevision}'\n\n# Sync and health status\nkubectl get application observability-stack -n argocd \\\n  -o jsonpath='{.status.sync.status}'\nkubectl get application observability-stack -n argocd \\\n  -o jsonpath='{.status.health.status}'\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#argocd-web-interface","title":"ArgoCD Web Interface","text":"<pre><code># Get admin password\nkubectl -n argocd get secret argocd-initial-admin-secret \\\n  -o jsonpath=\"{.data.password}\" | base64 -d &amp;&amp; echo\n\n# Port forward to ArgoCD UI\nkubectl port-forward svc/argocd-server -n argocd 8080:443 &amp;\n\n# Access at: https://localhost:8080 (admin/&lt;password&gt;)\n\n# Create ingress for permanent access\nkubectl apply -f manifests/argocd-ingress.yaml\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#force-sync","title":"Force Sync","text":"<pre><code># Automated sync script (recommended)\n./scripts/force_argo_sync.sh\n\n# Manual refresh\nkubectl patch application observability-stack -n argocd \\\n  -p '{\"metadata\":{\"annotations\":{\"argocd.argoproj.io/refresh\":\"hard\"}}}' \\\n  --type=merge\n\n# Manual sync\nkubectl patch application observability-stack -n argocd \\\n  -p '{\"operation\":{\"sync\":{\"syncStrategy\":{\"hook\":{}}}}}' \\\n  --type=merge\n\n# Apply ArgoCD application manifest\nkubectl apply -f argocd/observability-stack.yaml -n argocd\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#argocd-server-management","title":"ArgoCD Server Management","text":"<pre><code># Check ArgoCD server status\nkubectl get pods -n argocd | grep argocd-server\n\n# Restart ArgoCD server if needed\nkubectl delete pod -l app.kubernetes.io/name=argocd-server -n argocd\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#branch-verification","title":"Branch Verification","text":"<pre><code># Current Git branch\ngit rev-parse --abbrev-ref HEAD\n\n# ArgoCD targetRevision\nkubectl get application observability-stack -n argocd \\\n  -o jsonpath='{.spec.source.targetRevision}'\n\n# Should match! If not, sync:\n./scripts/force_argo_sync.sh\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#kubernetes-debugging","title":"Kubernetes Debugging","text":""},{"location":"guides/TROUBLESHOOTING/#pod-and-service-information","title":"Pod and Service Information","text":"<pre><code># List all pods\nkubectl get pods -n observability-lab\nkubectl get pods -n observability-lab -o wide\n\n# Describe specific pod\nkubectl describe pod &lt;pod-name&gt; -n observability-lab\n\n# Pod logs\nkubectl logs &lt;pod-name&gt; -n observability-lab\nkubectl logs &lt;pod-name&gt; -n observability-lab --tail=20 --follow\n\n# Logs for specific container\nkubectl logs &lt;pod-name&gt; -c &lt;container-name&gt; -n observability-lab\n\n# Previous container logs (for crashed pods)\nkubectl logs &lt;pod-name&gt; -n observability-lab --previous\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#services-and-endpoints","title":"Services and Endpoints","text":"<pre><code># List services\nkubectl get services -n observability-lab\n\n# List endpoints\nkubectl get endpoints -n observability-lab\n\n# Service details\nkubectl describe service &lt;service-name&gt; -n observability-lab\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#configmaps-and-secrets","title":"ConfigMaps and Secrets","text":"<pre><code># List configmaps\nkubectl get configmaps -n observability-lab\n\n# Show configmap contents\nkubectl get configmap &lt;configmap-name&gt; -n observability-lab -o yaml\n\n# List secrets\nkubectl get secrets -n observability-lab\n\n# Get secret value (base64 decoded)\nkubectl get secret &lt;secret-name&gt; -n observability-lab \\\n  -o jsonpath='{.data.&lt;key&gt;}' | base64 -d\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#resource-overview","title":"Resource Overview","text":"<pre><code># All resources\nkubectl get all -n observability-lab\n\n# Recent events\nkubectl get events -n observability-lab --sort-by=.metadata.creationTimestamp\n\n# Resource usage\nkubectl top pods -n observability-lab\nkubectl top nodes\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#loki-testing","title":"Loki Testing","text":""},{"location":"guides/TROUBLESHOOTING/#log-ingestion","title":"Log Ingestion","text":"<pre><code># Send single test log\ncurl -H \"Content-Type: application/json\" -H \"X-Scope-OrgID: foo\" \\\n  -XPOST \"http://loki.k8s.test/loki/api/v1/push\" \\\n  -d '{\n    \"streams\": [{\n      \"stream\": {\n        \"job\": \"test-job\",\n        \"service_name\": \"test-service\"\n      },\n      \"values\": [\n        [\"'$(date +%s%N)'\", \"Test log message\"]\n      ]\n    }]\n  }'\n\n# Send multiple logs (chunk testing)\ncurl -H \"Content-Type: application/json\" -H \"X-Scope-OrgID: foo\" \\\n  -XPOST \"http://loki.k8s.test/loki/api/v1/push\" \\\n  -d '{\n    \"streams\": [{\n      \"stream\": {\n        \"job\": \"multi-test\",\n        \"service_name\": \"batch-test\"\n      },\n      \"values\": [\n        [\"'$(date +%s%N)'\", \"First message\"],\n        [\"'$(date +%s%N)'\", \"Second message\"],\n        [\"'$(date +%s%N)'\", \"Third message\"]\n      ]\n    }]\n  }'\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#log-querying","title":"Log Querying","text":"<pre><code># Basic query\nlogcli query --addr=http://loki.k8s.test --org-id=\"foo\" \\\n  '{job=\"test-job\"}' --limit=100 --since=1h\n\n# Query specific service\nlogcli query --addr=http://loki.k8s.test --org-id=\"foo\" \\\n  '{service_name=\"test-service\"}' --limit=50 --since=30m\n\n# Pattern matching\nlogcli query --addr=http://loki.k8s.test --org-id=\"foo\" \\\n  '{job=~\"test.*\"}' --limit=200 --since=2h\n\n# Live tail\nlogcli query --addr=http://loki.k8s.test --org-id=\"foo\" \\\n  '{job=\"test-job\"}' --tail --since=1m\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#multi-tenant-testing","title":"Multi-Tenant Testing","text":"<pre><code># Test foo tenant\ncurl -H \"Content-Type: application/json\" -H \"X-Scope-OrgID: foo\" \\\n  -XPOST \"http://loki.k8s.test/loki/api/v1/push\" \\\n  -d '{\"streams\":[{\"stream\":{\"job\":\"foo-test\"},\"values\":[[\"'$(date +%s%N)'\",\"Test from foo\"]]}]}'\n\n# Test bazz tenant\ncurl -H \"Content-Type: application/json\" -H \"X-Scope-OrgID: bazz\" \\\n  -XPOST \"http://loki.k8s.test/loki/api/v1/push\" \\\n  -d '{\"streams\":[{\"stream\":{\"job\":\"bazz-test\"},\"values\":[[\"'$(date +%s%N)'\",\"Test from bazz\"]]}]}'\n\n# Verify tenant isolation\nlogcli query --addr=http://loki.k8s.test --org-id=\"foo\" \\\n  '{job=\"foo-test\"}' --limit=5 --since=5m\nlogcli query --addr=http://loki.k8s.test --org-id=\"bazz\" \\\n  '{job=\"bazz-test\"}' --limit=5 --since=5m\n\n# Check OTLP routing\nkubectl logs -n observability-lab deployment/otel-collector | grep -i routing\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#multi-tenant-checklist","title":"Multi-Tenant Checklist","text":"<ul> <li>[ ] Logs with <code>dev.audit.category</code> attribute go to bazz tenant</li> <li>[ ] Other logs go to foo tenant (default)</li> <li>[ ] Routing processor works: check OTLP collector logs</li> <li>[ ] Both Grafana datasources configured (Loki-foo and Loki-bazz)</li> </ul>"},{"location":"guides/TROUBLESHOOTING/#loki-configuration","title":"Loki Configuration","text":"<pre><code># Runtime configuration\nkubectl -n observability-lab exec loki-0 -- wget -qO- http://localhost:3100/config\n\n# Loki metrics\nkubectl -n observability-lab exec loki-0 -- wget -qO- http://localhost:3100/metrics\n\n# Ready status\nkubectl -n observability-lab exec loki-0 -- wget -qO- http://localhost:3100/ready\n\n# Loki logs with filtering\nkubectl logs loki-0 -n observability-lab --tail=20 | \\\n  grep -E \"(error|warn|chunk|flush|filesystem)\"\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#grafana-datasource-verification","title":"Grafana Datasource Verification","text":"<pre><code># Check datasource configuration\nkubectl get configmap grafana -n observability-lab -o yaml | grep -A5 \"loki\\|bazz\"\n\n# Test datasource connectivity from Grafana pod\nkubectl exec -it -n observability-lab deployment/grafana -- \\\n  wget -qO- \"http://loki-gateway:80/ready\"\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#tempotracing-testing","title":"Tempo/Tracing Testing","text":""},{"location":"guides/TROUBLESHOOTING/#trace-ingestion","title":"Trace Ingestion","text":"<pre><code># Send test trace via OTLP Collector (recommended)\ncurl -X POST http://otel-collector.k8s.test:4318/v1/traces \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"resourceSpans\": [{\n      \"resource\": {\n        \"attributes\": [{\n          \"key\": \"service.name\",\n          \"value\": {\"stringValue\": \"test-service\"}\n        }]\n      },\n      \"instrumentationLibrarySpans\": [{\n        \"spans\": [{\n          \"traceId\": \"'$(openssl rand -hex 16)'\",\n          \"spanId\": \"'$(openssl rand -hex 8)'\",\n          \"name\": \"test-span\",\n          \"kind\": 1,\n          \"startTimeUnixNano\": \"'$(($(date +%s) * 1000000000))'\",\n          \"endTimeUnixNano\": \"'$((($(date +%s) + 1) * 1000000000))'\"\n        }]\n      }]\n    }]\n  }'\n\n# Send directly to Tempo (requires port-forward)\nkubectl port-forward service/tempo 3200:3200 -n observability-lab &amp;\ncurl -X POST http://localhost:3200/v1/traces \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"resourceSpans\": [{\n      \"resource\": {\n        \"attributes\": [{\n          \"key\": \"service.name\",\n          \"value\": {\"stringValue\": \"direct-tempo-test\"}\n        }]\n      },\n      \"instrumentationLibrarySpans\": [{\n        \"spans\": [{\n          \"traceId\": \"'$(openssl rand -hex 16)'\",\n          \"spanId\": \"'$(openssl rand -hex 8)'\",\n          \"name\": \"direct-test-span\",\n          \"kind\": 1,\n          \"startTimeUnixNano\": \"'$(($(date +%s) * 1000000000))'\",\n          \"endTimeUnixNano\": \"'$((($(date +%s) + 1) * 1000000000))'\"\n        }]\n      }]\n    }]\n  }'\n</code></pre> <p>Important: Current configuration does NOT have Tempo search API enabled. Use Grafana to search and view traces.</p>"},{"location":"guides/TROUBLESHOOTING/#tempo-configuration","title":"Tempo Configuration","text":"<pre><code># Show Tempo configmap\nkubectl get configmap tempo -n observability-lab -o yaml\n\n# Check environment variables\nkubectl get pod tempo-0 -n observability-lab -o yaml | grep -A 10 -B 5 \"env:\"\n\n# Tempo logs\nkubectl logs tempo-0 -n observability-lab --tail=20\n\n# Tempo metrics\nkubectl -n observability-lab exec tempo-0 -- wget -qO- http://localhost:3200/metrics\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#tempo-storage-verification","title":"Tempo Storage Verification","text":"<pre><code># Verify traces written to filesystem\nkubectl -n observability-lab exec tempo-0 -- ls -lh /var/tempo/traces/\n\n# Check ingestion metrics\nkubectl -n observability-lab exec tempo-0 -- wget -qO- \"http://localhost:3200/metrics\" | \\\n  grep -E \"tempo_distributor|tempo_ingester\"\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#opentelemetry-collector-testing","title":"OpenTelemetry Collector Testing","text":""},{"location":"guides/TROUBLESHOOTING/#collector-status","title":"Collector Status","text":"<pre><code># Show collector logs\nkubectl logs -l app=otel-collector -n observability-lab --tail=20\n\n# Check configuration\nkubectl get configmap otel-collector -n observability-lab -o yaml\n\n# Test collector health\ncurl http://otel-collector.k8s.test:13133/\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#otlp-endpoints","title":"OTLP Endpoints","text":"<pre><code># Test OTLP HTTP endpoint (port 4318)\ncurl -X POST http://otel-collector.k8s.test:4318/v1/traces \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"resourceSpans\": [{\n      \"resource\": {\n        \"attributes\": [{\n          \"key\": \"service.name\",\n          \"value\": {\"stringValue\": \"curl-test\"}\n        }]\n      },\n      \"instrumentationLibrarySpans\": [{\n        \"spans\": [{\n          \"traceId\": \"'$(openssl rand -hex 16)'\",\n          \"spanId\": \"'$(openssl rand -hex 8)'\",\n          \"name\": \"test-operation\",\n          \"startTimeUnixNano\": \"'$(($(date +%s) * 1000000000))'\",\n          \"endTimeUnixNano\": \"'$((($(date +%s) + 1) * 1000000000))'\"\n        }]\n      }]\n    }]\n  }'\n\n# OTLP gRPC endpoint (port 4317)\n# Use OpenTelemetry SDK or grpcurl for testing\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#network-and-connectivity","title":"Network and Connectivity","text":""},{"location":"guides/TROUBLESHOOTING/#dns-resolution","title":"DNS Resolution","text":"<pre><code># Internal DNS (cluster services)\nkubectl run -it --rm debug --image=busybox --restart=Never -- \\\n  nslookup loki.observability-lab.svc.cluster.local\n\nkubectl run -it --rm debug --image=busybox --restart=Never -- \\\n  nslookup tempo.observability-lab.svc.cluster.local\n\n# External DNS (ingress)\nnslookup loki.k8s.test\nnslookup grafana.k8s.test\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#service-connectivity","title":"Service Connectivity","text":"<pre><code># Test internal service connectivity\nkubectl run -it --rm debug --image=curlimages/curl --restart=Never -- \\\n  curl -s http://loki.observability-lab.svc.cluster.local:3100/ready\n\nkubectl run -it --rm debug --image=curlimages/curl --restart=Never -- \\\n  curl -s http://tempo.observability-lab.svc.cluster.local:3200/ready\n\n# Test cross-service connectivity\nkubectl -n observability-lab exec deployment/grafana -- \\\n  wget -qO- http://loki:3100/ready\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#port-forwarding","title":"Port Forwarding","text":"<pre><code># Loki\nkubectl port-forward service/loki 3100:3100 -n observability-lab &amp;\n\n# Grafana\nkubectl port-forward service/grafana 3000:80 -n observability-lab &amp;\n\n# Prometheus\nkubectl port-forward service/prometheus 9090:80 -n observability-lab &amp;\n\n# Tempo\nkubectl port-forward service/tempo 3200:3200 -n observability-lab &amp;\n\n# List active port forwards\nps aux | grep \"kubectl port-forward\"\n\n# Stop all port forwards\npkill -f \"kubectl port-forward\"\n</code></pre> <p>Access URLs (when port-forwarding): - Grafana: http://localhost:3000 (admin/admin) - Loki: http://localhost:3100 - Prometheus: http://localhost:9090 - Tempo: http://localhost:3200</p>"},{"location":"guides/TROUBLESHOOTING/#ingress-testing","title":"Ingress Testing","text":"<pre><code># Test ingress endpoints\ncurl -s http://grafana.k8s.test\ncurl -s http://loki.k8s.test/ready\n\n# Check ingress resources\nkubectl get ingress -n observability-lab\nkubectl describe ingress &lt;ingress-name&gt; -n observability-lab\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#configuration-verification","title":"Configuration Verification","text":""},{"location":"guides/TROUBLESHOOTING/#environment-variables","title":"Environment Variables","text":"<pre><code># Loki environment\nkubectl get pod loki-0 -n observability-lab -o yaml | grep -A 20 \"env:\"\nkubectl -n observability-lab exec loki-0 -- env | sort\n\n# Tempo environment\nkubectl get pod tempo-0 -n observability-lab -o yaml | grep -A 20 \"env:\"\nkubectl -n observability-lab exec tempo-0 -- env | sort\n\n# Grafana environment\nkubectl get pod -n observability-lab -l app.kubernetes.io/name=grafana -o yaml | \\\n  grep -A 20 \"env:\"\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#volume-mounts","title":"Volume Mounts","text":"<pre><code># Loki volumes\nkubectl get pod loki-0 -n observability-lab -o yaml | \\\n  grep -A 10 -B 5 \"volumeMounts\"\n\n# Tempo volumes\nkubectl get pod tempo-0 -n observability-lab -o yaml | \\\n  grep -A 10 -B 5 \"volumeMounts\"\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#configuration-files","title":"Configuration Files","text":"<pre><code># Loki config\nkubectl -n observability-lab exec loki-0 -- cat /etc/loki/config/config.yaml\n\n# Tempo config\nkubectl -n observability-lab exec tempo-0 -- cat /etc/tempo/tempo.yaml\n\n# Prometheus config\nkubectl -n observability-lab exec deployment/prometheus -- \\\n  cat /etc/prometheus/prometheus.yml\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#performance-and-monitoring","title":"Performance and Monitoring","text":""},{"location":"guides/TROUBLESHOOTING/#resource-usage","title":"Resource Usage","text":"<pre><code># Pod resource usage\nkubectl top pods -n observability-lab\n\n# Node resource usage\nkubectl top nodes\nkubectl describe nodes | grep -E \"(Pressure|Allocatable|Allocated)\"\n\n# Resource requests and limits\nkubectl describe pods -n observability-lab | grep -E \"(Requests|Limits)\"\n\n# Detailed resource info\nkubectl describe pod &lt;pod-name&gt; -n observability-lab | \\\n  grep -A 10 -B 5 -E \"(Requests|Limits|Containers)\"\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#storage-usage","title":"Storage Usage","text":"<pre><code># Check PVC status\nkubectl get pvc -n observability-lab\n\n# PVC details\nkubectl describe pvc -n observability-lab\n\n# Disk usage in pods\nkubectl -n observability-lab exec loki-0 -- df -h /var/loki\nkubectl -n observability-lab exec tempo-0 -- df -h /var/tempo\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#application-metrics","title":"Application Metrics","text":"<pre><code># Loki metrics\ncurl http://loki.k8s.test:3100/metrics | grep loki_\n\n# Tempo metrics\ncurl http://tempo.k8s.test:3200/metrics | grep tempo_\n\n# Prometheus targets\ncurl http://prometheus.k8s.test/api/v1/targets\n\n# Grafana health\ncurl http://grafana.k8s.test/api/health\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#performance-testing","title":"Performance Testing","text":"<pre><code># Response times\ntime curl -s http://loki.k8s.test/ready\ntime curl -I http://grafana.k8s.test\n\n# Log ingestion performance\ntime curl -H \"Content-Type: application/json\" -H \"X-Scope-OrgID: foo\" \\\n  -XPOST \"http://loki.k8s.test/loki/api/v1/push\" \\\n  -d '{\"streams\":[{\"stream\":{\"job\":\"perf-test\"},\"values\":[[\"'$(date +%s%N)'\",\"Performance test\"]]}]}'\n\n# Query performance\ntime logcli query --addr=http://loki.k8s.test --org-id=\"foo\" \\\n  '{job=\"perf-test\"}' --limit=1 --since=1h\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#troubleshooting-playbook","title":"Troubleshooting Playbook","text":""},{"location":"guides/TROUBLESHOOTING/#issue-pod-not-readyrunning","title":"Issue: Pod Not Ready/Running","text":"<pre><code># Step 1: Check pod status\nkubectl get pods -n observability-lab\nkubectl describe pod &lt;pod-name&gt; -n observability-lab\n\n# Step 2: Check recent events\nkubectl get events -n observability-lab --sort-by=.metadata.creationTimestamp\n\n# Step 3: Check logs\nkubectl logs &lt;pod-name&gt; -n observability-lab --previous\nkubectl logs &lt;pod-name&gt; -n observability-lab\n\n# Step 4: Check resource constraints\nkubectl describe pod &lt;pod-name&gt; -n observability-lab | grep -E \"(Requests|Limits)\"\n\n# Step 5: Restart pod if necessary\nkubectl delete pod &lt;pod-name&gt; -n observability-lab\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#issue-service-not-accessible","title":"Issue: Service Not Accessible","text":"<pre><code># Step 1: Check service endpoints\nkubectl get endpoints &lt;service-name&gt; -n observability-lab\n\n# Step 2: Test internal connectivity\nkubectl run -it --rm debug --image=curlimages/curl --restart=Never -- \\\n  curl -v http://&lt;service-name&gt;.observability-lab.svc.cluster.local:&lt;port&gt;\n\n# Step 3: Check network policies\nkubectl get networkpolicies -n observability-lab\n\n# Step 4: Check ingress configuration\nkubectl get ingress -n observability-lab\nkubectl describe ingress &lt;ingress-name&gt; -n observability-lab\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#issue-storage-problems-filesystem","title":"Issue: Storage Problems (Filesystem)","text":"<pre><code># Step 1: Check PVC status\nkubectl get pvc -n observability-lab\nkubectl describe pvc -n observability-lab\n\n# Step 2: Check disk space\nkubectl -n observability-lab exec loki-0 -- df -h /var/loki\nkubectl -n observability-lab exec tempo-0 -- df -h /var/tempo\n\n# Step 3: Check for permission issues\nkubectl logs loki-0 -n observability-lab | grep -i \"permission denied\"\nkubectl logs tempo-0 -n observability-lab | grep -i \"permission denied\"\n\n# Step 4: Check PV status\nkubectl get pv\nkubectl describe pv &lt;pv-name&gt;\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#issue-argocd-sync-problems","title":"Issue: ArgoCD Sync Problems","text":"<pre><code># Step 1: Check application status\nkubectl get application observability-stack -n argocd\nkubectl get application observability-stack -n argocd -o yaml\n\n# Step 2: Force refresh and sync\n./scripts/force_argo_sync.sh\n\n# Step 3: Check Git connectivity\nkubectl get application observability-stack -n argocd \\\n  -o jsonpath='{.status.conditions}'\n\n# Step 4: Check targetRevision matches Git branch\ngit rev-parse --abbrev-ref HEAD\nkubectl get application observability-stack -n argocd \\\n  -o jsonpath='{.spec.source.targetRevision}'\n\n# Step 5: Recreate application if necessary\nkubectl delete application observability-stack -n argocd\nkubectl apply -f argocd/observability-stack.yaml -n argocd\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#issue-no-logstraces-appearing","title":"Issue: No Logs/Traces Appearing","text":"<pre><code># Step 1: Verify component is running\nkubectl get pods -n observability-lab | grep -E \"loki|tempo|otel\"\n\n# Step 2: Check OTLP Collector\nkubectl logs -l app=otel-collector -n observability-lab --tail=50\n\n# Step 3: Test direct ingestion\n# For Loki:\ncurl -H \"Content-Type: application/json\" -H \"X-Scope-OrgID: foo\" \\\n  -XPOST \"http://loki.k8s.test/loki/api/v1/push\" \\\n  -d '{\"streams\":[{\"stream\":{\"job\":\"debug\"},\"values\":[[\"'$(date +%s%N)'\",\"Debug test\"]]}]}'\n\n# Step 4: Check storage\nkubectl -n observability-lab exec loki-0 -- ls -lh /var/loki/chunks/\nkubectl -n observability-lab exec tempo-0 -- ls -lh /var/tempo/traces/\n\n# Step 5: Check Grafana datasource configuration\nkubectl get configmap grafana -n observability-lab -o yaml\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#issue-grafana-datasources-not-working","title":"Issue: Grafana Datasources Not Working","text":"<pre><code># Step 1: Check datasource configuration\nkubectl get configmap grafana -n observability-lab -o yaml | \\\n  grep -A 20 \"datasources\"\n\n# Step 2: Test connectivity from Grafana pod\nkubectl exec -it -n observability-lab deployment/grafana -- \\\n  wget -qO- http://loki-gateway:80/ready\n\nkubectl exec -it -n observability-lab deployment/grafana -- \\\n  wget -qO- http://tempo:3200/ready\n\n# Step 3: Check Grafana logs\nkubectl logs -n observability-lab deployment/grafana --tail=50\n\n# Step 4: Restart Grafana\nkubectl delete pod -n observability-lab -l app.kubernetes.io/name=grafana\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#storage-backend","title":"Storage Backend","text":"<p>Current Configuration: Local filesystem storage via PVCs</p>"},{"location":"guides/TROUBLESHOOTING/#pvc-commands","title":"PVC Commands","text":""},{"location":"guides/TROUBLESHOOTING/#list-all-pvcs-kubectl-get-pvc-n-observability-lab-list-all-pvs-kubectl-get-pv-pvcs-for-specific-component-kubectl-get-pv-l-appkubernetesionameloki-kubectl-get-pv-l-appkubernetesionametempo-pvc-details-kubectl-describe-pvc-n-observability-lab","title":"<pre><code># List all PVCs\nkubectl get pvc -n observability-lab\n\n# List all PVs\nkubectl get pv\n\n# PVCs for specific component\nkubectl get pv -l app.kubernetes.io/name=loki\nkubectl get pv -l app.kubernetes.io/name=tempo\n\n# PVC details\nkubectl describe pvc -n observability-lab\n</code></pre>","text":""},{"location":"guides/TROUBLESHOOTING/#cleanup-and-uninstall","title":"Cleanup and Uninstall","text":""},{"location":"guides/TROUBLESHOOTING/#quick-cleanup-keep-cluster-running","title":"Quick Cleanup - Keep Cluster Running","text":"<p>Remove the observability stack but keep ArgoCD and cluster infrastructure:</p> <pre><code># 1. Delete the ArgoCD application (keeps ArgoCD itself)\nkubectl delete application observability-stack -n argocd\n\n# 2. Verify resources are being removed\nkubectl get pods -n observability-lab --watch\n\n# 3. Clean up namespace (if empty)\nkubectl delete namespace observability-lab\n\n# 4. Remove ingress rules\nkubectl delete ingress -n observability-lab --all\n\n# 5. Clean up any orphaned PVCs (\u26a0\ufe0f deletes data!)\nkubectl get pvc -n observability-lab\nkubectl delete pvc --all -n observability-lab\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#full-uninstall","title":"Full Uninstall","text":"<p>Remove everything including ArgoCD:</p> <pre><code># 1. Delete observability stack\nkubectl delete application observability-stack -n argocd\n\n# 2. Wait for resources to be removed\nkubectl wait --for=delete namespace/observability-lab --timeout=120s || true\n\n# 3. Uninstall ArgoCD\nkubectl delete namespace argocd\n\n# 4. Remove ArgoCD CRDs\nkubectl delete crd applications.argoproj.io\nkubectl delete crd applicationsets.argoproj.io\nkubectl delete crd appprojects.argoproj.io\n\n# 5. Clean up any remaining PVs (\u26a0\ufe0f deletes all data!)\nkubectl get pv | grep observability-lab\nkubectl delete pv -l app.kubernetes.io/part-of=observability-stack\n\n# 6. Remove local Git repository artifacts (optional)\nrm -rf /Users/faar/Documents/Src/github/fiddeb/observabilitystack/helm/stackcharts/charts/*.tgz\nrm -f /Users/faar/Documents/Src/github/fiddeb/observabilitystack/helm/stackcharts/Chart.lock\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#selective-component-removal","title":"Selective Component Removal","text":"<p>Remove individual components while keeping the rest:</p>"},{"location":"guides/TROUBLESHOOTING/#disable-component-via-helm-values","title":"Disable Component via Helm Values","text":"<pre><code># 1. Edit helm/stackcharts/values/base.yaml\n# Set component.enabled: false (e.g., tempo.enabled: false)\n\n# 2. Commit and push changes\ngit add helm/stackcharts/values/base.yaml\ngit commit -m \"feat: disable tempo component\"\ngit push origin main\n\n# 3. Force ArgoCD sync\n./scripts/force_argo_sync.sh\n\n# 4. Clean up component PVCs (\u26a0\ufe0f deletes data!)\nkubectl delete pvc -l app.kubernetes.io/name=tempo -n observability-lab\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#manual-component-removal","title":"Manual Component Removal","text":"<pre><code># Example: Remove Tempo\nkubectl delete statefulset tempo -n observability-lab\nkubectl delete service tempo -n observability-lab\nkubectl delete configmap tempo -n observability-lab\nkubectl delete pvc -l app.kubernetes.io/name=tempo -n observability-lab\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#reset-to-clean-state","title":"Reset to Clean State","text":"<p>Start fresh without reinstalling cluster:</p> <pre><code># 1. Remove observability stack\nkubectl delete application observability-stack -n argocd\nkubectl delete namespace observability-lab --wait=true\n\n# 2. Recreate namespace\nkubectl create namespace observability-lab\n\n# 3. Reinstall via ArgoCD\n./scripts/force_argo_sync.sh\n\n# 4. Wait for healthy state\nkubectl wait --for=condition=ready pod --all -n observability-lab --timeout=300s\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#dns-cleanup-macoslinux","title":"DNS Cleanup (macOS/Linux)","text":"<p>If you want to remove the <code>*.k8s.test</code> DNS configuration:</p>"},{"location":"guides/TROUBLESHOOTING/#macos","title":"macOS","text":"<pre><code># 1. Remove resolver configuration\nsudo rm /etc/resolver/k8s.test\n\n# 2. Restart DNS (optional)\nsudo killall -HUP mDNSResponder\n\n# 3. Remove dnsmasq configuration (if you want to uninstall dnsmasq)\n# Edit /opt/homebrew/etc/dnsmasq.conf and remove: address=/.k8s.test/127.0.0.1\nbrew services stop dnsmasq\n# brew uninstall dnsmasq  # Only if you don't need it for anything else\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#linux","title":"Linux","text":"<pre><code># 1. Remove dnsmasq configuration\nsudo sed -i '/address=\\/.k8s.test\\/127.0.0.1/d' /etc/dnsmasq.conf\n\n# 2. Restart dnsmasq\nsudo systemctl restart dnsmasq\n# or\nsudo service dnsmasq restart\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#verification-after-cleanup","title":"Verification After Cleanup","text":"<p>Confirm everything is removed:</p> <pre><code># Check namespaces\nkubectl get namespace | grep -E 'observability-lab|argocd'\n\n# Check PVs (should show none for observability-lab)\nkubectl get pv | grep observability-lab\n\n# Check ingress\nkubectl get ingress --all-namespaces\n\n# Test DNS (should fail or timeout)\ncurl -s --max-time 5 http://grafana.k8s.test || echo \"\u2705 Grafana endpoint removed\"\ncurl -s --max-time 5 http://loki.k8s.test/ready || echo \"\u2705 Loki endpoint removed\"\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#troubleshooting-cleanup-issues","title":"Troubleshooting Cleanup Issues","text":""},{"location":"guides/TROUBLESHOOTING/#namespace-stuck-in-terminating","title":"Namespace Stuck in Terminating","text":"<pre><code># 1. Check for finalizers\nkubectl get namespace observability-lab -o json | jq '.spec.finalizers'\n\n# 2. Force remove finalizers (use with caution!)\nkubectl get namespace observability-lab -o json \\\n  | jq 'del(.spec.finalizers)' \\\n  | kubectl replace --raw /api/v1/namespaces/observability-lab/finalize -f -\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#pvcs-wont-delete","title":"PVCs Won't Delete","text":"<pre><code># 1. Check if PVC is bound to pods\nkubectl get pods -n observability-lab -o json | \\\n  jq '.items[].spec.volumes[].persistentVolumeClaim.claimName'\n\n# 2. Delete pods using the PVC first\nkubectl delete pod &lt;pod-name&gt; -n observability-lab --force --grace-period=0\n\n# 3. Then delete PVC\nkubectl delete pvc &lt;pvc-name&gt; -n observability-lab\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#argocd-application-wont-delete","title":"ArgoCD Application Won't Delete","text":"<pre><code># 1. Check finalizers\nkubectl get application observability-stack -n argocd -o yaml | grep finalizers -A5\n\n# 2. Remove finalizers if stuck\nkubectl patch application observability-stack -n argocd \\\n  -p '{\"metadata\":{\"finalizers\":null}}' --type=merge\n\n# 3. Force delete\nkubectl delete application observability-stack -n argocd --force --grace-period=0\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#useful-shortcuts-and-aliases","title":"Useful Shortcuts and Aliases","text":"<p>Add these to your <code>~/.zshrc</code> or <code>~/.bashrc</code>:</p> <pre><code># Kubernetes aliases\nalias k='kubectl'\nalias kgp='kubectl get pods'\nalias kgs='kubectl get services'\nalias kgc='kubectl get configmaps'\nalias kd='kubectl describe'\nalias kl='kubectl logs'\nalias ke='kubectl exec -it'\n\n# Observability namespace shortcuts\nalias kobs='kubectl -n observability-lab'\nalias kobspods='kubectl get pods -n observability-lab'\nalias kobslogs='kubectl logs -n observability-lab'\n\n# ArgoCD shortcuts\nalias argoapp='kubectl get application observability-stack -n argocd'\nalias argosync='./scripts/force_argo_sync.sh'\n\n# Port forwarding shortcuts\nalias pf-grafana='kubectl port-forward service/grafana 3000:80 -n observability-lab &amp;'\nalias pf-loki='kubectl port-forward service/loki 3100:3100 -n observability-lab &amp;'\nalias pf-tempo='kubectl port-forward service/tempo 3200:3200 -n observability-lab &amp;'\nalias pf-prometheus='kubectl port-forward service/prometheus 9090:80 -n observability-lab &amp;'\n\n# Stop all port forwards\nalias pf-stop='pkill -f \"kubectl port-forward\"'\n</code></pre>"},{"location":"guides/TROUBLESHOOTING/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture Guide - System design</li> <li>Installation Guide - Setup instructions</li> <li>Usage Guide - How to use the stack</li> <li>Git Workflow - Branch and merge procedures</li> </ul> <p>Last Updated: October 2, 2025</p>"},{"location":"guides/USAGE_GUIDE/","title":"Usage Guide","text":"<p>How to use the ObservabilityStack for learning and experimenting with telemetry data.</p> <p>\ud83d\udca1 Lab Environment: This guide assumes you're using the lab setup with default settings. Good for learning observability concepts!</p>"},{"location":"guides/USAGE_GUIDE/#overview","title":"Overview","text":"<p>The ObservabilityStack includes: - OpenTelemetry Collector as the central telemetry ingestion point - Loki for log storage and querying (local filesystem) with multi-tenant support - Tempo for distributed tracing (local filesystem) - Prometheus for metrics collection - Grafana for visualization with tenant-specific datasources</p>"},{"location":"guides/USAGE_GUIDE/#multi-tenant-setup","title":"Multi-Tenant Setup","text":"<p>The platform uses multiple tenants to isolate logs: - 'foo' tenant - Default tenant for general logs - 'bazz' tenant - Separate tenant for audit logs - Automatic routing based on log attributes via OpenTelemetry Collector - Separate Grafana datasources for each tenant</p>"},{"location":"guides/USAGE_GUIDE/#data-flow","title":"Data Flow","text":"<pre><code>Applications \u2192 OpenTelemetry Collector \u2192 Backends \u2192 Grafana\n</code></pre> <ul> <li>Logs \u2192 OpenTelemetry Collector \u2192 Loki (local filesystem) \u2192 Grafana</li> <li>Metrics \u2192 OpenTelemetry Collector \u2192 Prometheus \u2192 Grafana  </li> <li>Traces \u2192 OpenTelemetry Collector \u2192 Tempo (local filesystem) \u2192 Grafana</li> </ul>"},{"location":"guides/USAGE_GUIDE/#sending-telemetry-data","title":"Sending Telemetry Data","text":""},{"location":"guides/USAGE_GUIDE/#opentelemetry-collector-endpoints","title":"OpenTelemetry Collector Endpoints","text":"<p>Internal (from within cluster): - gRPC: <code>otel-collector.observability-lab.svc.cluster.local:4317</code> - HTTP: <code>otel-collector.observability-lab.svc.cluster.local:4318</code></p> <p>External (via ingress): - HTTP: <code>http://otel-collector.k8s.test</code></p>"},{"location":"guides/USAGE_GUIDE/#example-sending-logs","title":"Example: Sending Logs","text":""},{"location":"guides/USAGE_GUIDE/#via-otlp-http","title":"Via OTLP HTTP","text":"<pre><code>curl -X POST http://otel-collector.k8s.test/v1/logs \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"resourceLogs\": [{\n      \"resource\": {\n        \"attributes\": [\n          {\"key\": \"service.name\", \"value\": {\"stringValue\": \"my-service\"}},\n          {\"key\": \"service.version\", \"value\": {\"stringValue\": \"1.0.0\"}}\n        ]\n      },\n      \"scopeLogs\": [{\n        \"logRecords\": [{\n          \"timeUnixNano\": \"'$(date +%s)'000000000\",\n          \"body\": {\"stringValue\": \"Application started successfully\"},\n          \"severityText\": \"INFO\",\n          \"attributes\": [\n            {\"key\": \"user.id\", \"value\": {\"stringValue\": \"user123\"}},\n            {\"key\": \"action\", \"value\": {\"stringValue\": \"startup\"}}\n          ]\n        }]\n      }]\n    }]\n  }'\n</code></pre>"},{"location":"guides/USAGE_GUIDE/#direct-to-loki-multi-tenant","title":"Direct to Loki (Multi-Tenant)","text":"<p>Send to 'foo' tenant: <pre><code>curl -H \"Content-Type: application/json\" \\\n     -H \"X-Scope-OrgID: foo\" \\\n     -XPOST \"http://loki.k8s.test/loki/api/v1/push\" \\\n     -d '{\n       \"streams\": [{\n         \"stream\": {\n           \"job\": \"my-application\",\n           \"level\": \"info\",\n           \"service\": \"my-service\"\n         },\n         \"values\": [\n           [\"'$(date +%s%N)'\", \"Log message to foo tenant\"]\n         ]\n       }]\n     }'\n</code></pre></p> <p>Send to 'bazz' tenant: <pre><code>curl -H \"Content-Type: application/json\" \\\n     -H \"X-Scope-OrgID: bazz\" \\\n     -XPOST \"http://loki.k8s.test/loki/api/v1/push\" \\\n     -d '{\n       \"streams\": [{\n         \"stream\": {\n           \"job\": \"audit-service\",\n           \"level\": \"info\", \n           \"category\": \"audit\"\n         },\n         \"values\": [\n           [\"'$(date +%s%N)'\", \"Audit log message to bazz tenant\"]\n         ]\n       }]\n     }'\n</code></pre></p>"},{"location":"guides/USAGE_GUIDE/#example-sending-metrics","title":"Example: Sending Metrics","text":"<pre><code>curl -X POST http://otel-collector.k8s.test/v1/metrics \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"resourceMetrics\": [{\n      \"resource\": {\n        \"attributes\": [\n          {\"key\": \"service.name\", \"value\": {\"stringValue\": \"my-service\"}},\n          {\"key\": \"host.name\", \"value\": {\"stringValue\": \"web-server-01\"}}\n        ]\n      },\n      \"scopeMetrics\": [{\n        \"metrics\": [{\n          \"name\": \"http_requests_total\",\n          \"description\": \"Total HTTP requests\",\n          \"unit\": \"1\",\n          \"sum\": {\n            \"dataPoints\": [{\n              \"timeUnixNano\": \"'$(date +%s)'000000000\",\n              \"asInt\": \"157\",\n              \"attributes\": [\n                {\"key\": \"method\", \"value\": {\"stringValue\": \"GET\"}},\n                {\"key\": \"status\", \"value\": {\"stringValue\": \"200\"}}\n              ]\n            }],\n            \"aggregationTemporality\": 2,\n            \"isMonotonic\": true\n          }\n        }]\n      }]\n    }]\n  }'\n</code></pre>"},{"location":"guides/USAGE_GUIDE/#example-sending-traces","title":"Example: Sending Traces","text":"<pre><code>curl -X POST http://otel-collector.k8s.test/v1/traces \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"resourceSpans\": [{\n      \"resource\": {\n        \"attributes\": [\n          {\"key\": \"service.name\", \"value\": {\"stringValue\": \"my-service\"}},\n          {\"key\": \"service.version\", \"value\": {\"stringValue\": \"1.0.0\"}}\n        ]\n      },\n      \"scopeSpans\": [{\n        \"spans\": [{\n          \"traceId\": \"'$(openssl rand -hex 16)'\",\n          \"spanId\": \"'$(openssl rand -hex 8)'\",\n          \"name\": \"HTTP GET /api/users\",\n          \"kind\": 3,\n          \"startTimeUnixNano\": \"'$(($(date +%s) * 1000000000))'\",\n          \"endTimeUnixNano\": \"'$((($(date +%s) + 2) * 1000000000))'\",\n          \"attributes\": [\n            {\"key\": \"http.method\", \"value\": {\"stringValue\": \"GET\"}},\n            {\"key\": \"http.url\", \"value\": {\"stringValue\": \"/api/users\"}},\n            {\"key\": \"http.status_code\", \"value\": {\"intValue\": \"200\"}}\n          ],\n          \"status\": {\"code\": 1}\n        }]\n      }]\n    }]\n  }'\n</code></pre>"},{"location":"guides/USAGE_GUIDE/#automatic-tenant-routing-via-opentelemetry","title":"Automatic Tenant Routing via OpenTelemetry","text":"<p>The OpenTelemetry Collector automatically routes logs to different tenants based on attributes:</p> <p>Route to 'bazz' tenant (audit logs): <pre><code>curl -X POST http://otel-collector.k8s.test/v1/logs \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"resourceLogs\": [{\n      \"resource\": {\n        \"attributes\": [\n          {\"key\": \"service.name\", \"value\": {\"stringValue\": \"audit-service\"}}\n        ]\n      },\n      \"scopeLogs\": [{\n        \"logRecords\": [{\n          \"timeUnixNano\": \"'$(date +%s)'000000000\",\n          \"body\": {\"stringValue\": \"User login successful\"},\n          \"severityText\": \"INFO\",\n          \"attributes\": [\n            {\"key\": \"dev.audit.category\", \"value\": {\"stringValue\": \"authentication\"}},\n            {\"key\": \"user.id\", \"value\": {\"stringValue\": \"user123\"}}\n          ]\n        }]\n      }]\n    }]\n  }'\n</code></pre></p> <p>Route to 'foo' tenant (default logs): <pre><code>curl -X POST http://otel-collector.k8s.test/v1/logs \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"resourceLogs\": [{\n      \"resource\": {\n        \"attributes\": [\n          {\"key\": \"service.name\", \"value\": {\"stringValue\": \"web-service\"}}\n        ]\n      },\n      \"scopeLogs\": [{\n        \"logRecords\": [{\n          \"timeUnixNano\": \"'$(date +%s)'000000000\",\n          \"body\": {\"stringValue\": \"HTTP request processed\"},\n          \"severityText\": \"INFO\",\n          \"attributes\": [\n            {\"key\": \"http.method\", \"value\": {\"stringValue\": \"GET\"}},\n            {\"key\": \"http.status_code\", \"value\": {\"intValue\": 200}}\n          ]\n        }]\n      }]\n    }]\n  }'\n</code></pre></p> <p>Routing Logic: If your log has a <code>dev.audit.category</code> attribute, it goes to the 'bazz' tenant. Everything else goes to 'foo'.</p>"},{"location":"guides/USAGE_GUIDE/#using-grafana","title":"Using Grafana","text":""},{"location":"guides/USAGE_GUIDE/#access-grafana","title":"Access Grafana","text":"<ul> <li>URL: http://grafana.k8s.test</li> <li>No login required (anonymous access enabled)</li> </ul>"},{"location":"guides/USAGE_GUIDE/#data-sources","title":"Data Sources","text":"<p>The following data sources are already set up:</p> <ol> <li>Prometheus - Metrics from OpenTelemetry Collector</li> <li>Loki (foo tenant) - Default logs from 'foo' tenant</li> <li>Loki (bazz tenant) - Audit logs from 'bazz' tenant  </li> <li>Tempo - Distributed traces with service map</li> </ol> <p>Multi-Tenant Logs: Each Loki datasource connects to a specific tenant using the <code>X-Scope-OrgID</code> header for data isolation.</p>"},{"location":"guides/USAGE_GUIDE/#querying-data","title":"Querying Data","text":""},{"location":"guides/USAGE_GUIDE/#prometheus-queries","title":"Prometheus Queries","text":"<pre><code># HTTP request rate\nrate(http_requests_total[5m])\n\n# Memory usage\ncontainer_memory_usage_bytes\n\n# Custom metrics from OpenTelemetry\ngen{}\n</code></pre>"},{"location":"guides/USAGE_GUIDE/#loki-queries","title":"Loki Queries","text":"<p>From 'foo' tenant datasource: <pre><code># All logs from a service\n{service_name=\"my-service\"}\n\n# Error logs only\n{service_name=\"my-service\"} |= \"error\"\n\n# Web service logs\n{job=\"my-application\", level=\"info\"}\n\n# Count requests per minute\nsum(count_over_time({service_name=\"web-service\"} |~ \"HTTP request\" [1m])) by (service_name)\n</code></pre></p> <p>From 'bazz' tenant datasource (audit logs): <pre><code># All audit logs\n{job=\"audit-service\"}\n\n# Authentication events\n{job=\"audit-service\"} |= \"login\"\n\n# Failed authentication attempts\n{category=\"audit\"} |= \"failed\"\n\n# Count audit events per hour\nsum(count_over_time({category=\"audit\"} [1h])) by (category)\n</code></pre></p> <p>Tenant Isolation: Switch between datasources in Grafana to view logs from different tenants.</p>"},{"location":"guides/USAGE_GUIDE/#tempo-queries","title":"Tempo Queries","text":"<pre><code># Search by service name\n{service.name=\"my-service\"}\n\n# Search by operation\n{name=\"HTTP GET /api/users\"}\n\n# Search by trace ID\n{traceID=\"abc123def456\"}\n</code></pre>"},{"location":"guides/USAGE_GUIDE/#testing-the-pipeline","title":"Testing the Pipeline","text":""},{"location":"guides/USAGE_GUIDE/#automated-tests","title":"Automated Tests","text":"<p>Run the automated tests:</p> <pre><code># Deploy test jobs\nkubectl apply -f manifests/telemetry-test-jobs.yaml\n\n# Wait for completion\nkubectl wait --for=condition=complete job/telemetrygen-metrics -n observability-lab --timeout=60s\nkubectl wait --for=condition=complete job/telemetrygen-logs -n observability-lab --timeout=60s\nkubectl wait --for=condition=complete job/telemetrygen-traces -n observability-lab --timeout=60s\n</code></pre>"},{"location":"guides/USAGE_GUIDE/#manual-verification","title":"Manual Verification","text":""},{"location":"guides/USAGE_GUIDE/#check-log-ingestion","title":"Check Log Ingestion","text":"<pre><code># Send test log\ncurl -H \"Content-Type: application/json\" -H \"X-Scope-OrgID: foo\" \\\n     -XPOST \"http://loki.k8s.test/loki/api/v1/push\" \\\n     -d '{\"streams\":[{\"stream\":{\"job\":\"test\"},\"values\":[[\"'$(date +%s%N)'\",\"Test log message\"]]}]}'\n\n# Query logs\nlogcli query --addr=http://loki.k8s.test --org-id=\"foo\" '{job=\"test\"}' --limit=10 --since=5m\n</code></pre>"},{"location":"guides/USAGE_GUIDE/#check-local-storage","title":"Check Local Storage","text":"<pre><code># Check Loki persistent volume data\nkubectl get pv -l app.kubernetes.io/name=loki\n\n# Check Tempo persistent volume data  \nkubectl get pv -l app.kubernetes.io/name=tempo\n\n# Check actual data in Loki pod\nkubectl -n observability-lab exec -it deployment/loki -- ls -la /var/loki/\n\n# Check actual data in Tempo pod\nkubectl -n observability-lab exec -it deployment/tempo -- ls -la /var/tempo/\n</code></pre>"},{"location":"guides/USAGE_GUIDE/#application-integration","title":"Application Integration","text":""},{"location":"guides/USAGE_GUIDE/#opentelemetry-sdks","title":"OpenTelemetry SDKs","text":"<p>Configure your applications to send telemetry to the OpenTelemetry Collector:</p> <p>Environment Variables: <pre><code>export OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector.k8s.test\nexport OTEL_SERVICE_NAME=my-application\nexport OTEL_RESOURCE_ATTRIBUTES=service.version=1.0.0,environment=production\n</code></pre></p> <p>For internal cluster applications: <pre><code>export OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector.observability-lab.svc.cluster.local:4318\n</code></pre></p>"},{"location":"guides/USAGE_GUIDE/#kubernetes-applications","title":"Kubernetes Applications","text":"<p>Add OpenTelemetry auto-instrumentation to your deployments:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\nspec:\n  template:\n    spec:\n      containers:\n      - name: app\n        image: my-app:latest\n        env:\n        - name: OTEL_EXPORTER_OTLP_ENDPOINT\n          value: \"http://otel-collector.observability-lab.svc.cluster.local:4318\"\n        - name: OTEL_SERVICE_NAME\n          value: \"my-application\"\n        - name: OTEL_RESOURCE_ATTRIBUTES\n          value: \"service.version=1.0.0,environment=production\"\n</code></pre>"},{"location":"guides/USAGE_GUIDE/#storage-and-retention","title":"Storage and Retention","text":""},{"location":"guides/USAGE_GUIDE/#local-filesystem-storage","title":"Local Filesystem Storage","text":"<ul> <li>Loki logs: Stored on local filesystem in persistent volumes  </li> <li>Tempo traces: Stored on local filesystem in persistent volumes</li> <li>Persistence: Data persists across pod restarts via PersistentVolumes</li> <li>Lab environment: No S3 configuration needed</li> </ul>"},{"location":"guides/USAGE_GUIDE/#check-storage-usage","title":"Check Storage Usage","text":"<pre><code># Check persistent volume claims\nkubectl get pvc -n observability-lab\n\n# Check persistent volumes\nkubectl get pv\n\n# Get storage usage for Loki\nkubectl -n observability-lab exec deployment/loki -- df -h /var/loki\n\n# Get storage usage for Tempo  \nkubectl -n observability-lab exec deployment/tempo -- df -h /var/tempo\n</code></pre>"},{"location":"guides/USAGE_GUIDE/#monitoring-and-alerts","title":"Monitoring and Alerts","text":""},{"location":"guides/USAGE_GUIDE/#stack-metrics","title":"Stack Metrics","text":"<p>The stack exposes metrics for monitoring itself:</p> <ul> <li>Loki metrics: http://loki.k8s.test:3100/metrics</li> <li>Tempo metrics: http://tempo.k8s.test:3200/metrics  </li> <li>Prometheus metrics: http://prometheus.k8s.test/metrics</li> <li>OTEL Collector metrics: Available in Prometheus</li> </ul>"},{"location":"guides/USAGE_GUIDE/#health-checks","title":"Health Checks","text":"<pre><code># Check service health\ncurl http://loki.k8s.test/ready\ncurl http://tempo.k8s.test/ready\ncurl http://prometheus.k8s.test/-/ready\n\n# Automated health check\n./scripts/force_argo_sync.sh\n</code></pre>"},{"location":"guides/USAGE_GUIDE/#advanced","title":"Advanced","text":""},{"location":"guides/USAGE_GUIDE/#multi-tenancy","title":"Multi-tenancy","text":"<p>Loki supports multi-tenancy via the <code>X-Scope-OrgID</code> header:</p> <p><pre><code># Tenant \"production\"\ncurl -H \"X-Scope-OrgID: production\" ...\n\n# Tenant \"staging\"  \ncurl -H \"X-Scope-OrgID: staging\" ...\n</code></pre> <pre><code>### Custom Configuration\nModify values in `helm/stackcharts/values.yaml` and apply:\n\n```bash\n# Edit configuration\nvim helm/stackcharts/values.yaml\n\n# Apply changes\n./scripts/force_argo_sync.sh\n</code></pre></p>"},{"location":"guides/USAGE_GUIDE/#troubleshooting","title":"Troubleshooting","text":"<p>For detailed troubleshooting, see Troubleshooting Guide.</p>"}]}